{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data from the DataFrame\n",
    "data_files1 = pd.read_csv(r'\\Users\\mahin\\Downloads\\combined_file.csv')  # Load your combined csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['currentLinkStatus', 'lossTime', 'linkQuality', 'neighborLinkQuality1', 'RSSI value', 'trend', 'tau']\n",
    "target = ['Connected']\n",
    "\n",
    "data_files1['currentLinkStatus'] = data_files1['currentLinkStatus'].astype('category').cat.codes\n",
    "\n",
    "# Scaling the features\n",
    "scaler = MinMaxScaler()\n",
    "data_files1[features] = scaler.fit_transform(data_files1[features])\n",
    "\n",
    "# Convert DataFrame to PyTorch tensors\n",
    "X = torch.tensor(data_files1[features].values, dtype=torch.float32)\n",
    "y = torch.tensor(data_files1[target].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Generator Loss: 0.7083204388618469, Discriminator Loss: 1.3485021591186523\n",
      "Epoch [10/100], Generator Loss: 0.9437796473503113, Discriminator Loss: 1.0594536066055298\n",
      "Epoch [20/100], Generator Loss: 0.776383638381958, Discriminator Loss: 1.569658875465393\n",
      "Epoch [30/100], Generator Loss: 0.5938743948936462, Discriminator Loss: 1.768643856048584\n",
      "Epoch [40/100], Generator Loss: 0.7150800228118896, Discriminator Loss: 1.2978930473327637\n",
      "Epoch [50/100], Generator Loss: 0.9154263138771057, Discriminator Loss: 1.245478630065918\n",
      "Epoch [60/100], Generator Loss: 0.9170353412628174, Discriminator Loss: 1.229933261871338\n",
      "Epoch [70/100], Generator Loss: 0.7018744945526123, Discriminator Loss: 1.4080681800842285\n",
      "Epoch [80/100], Generator Loss: 0.7083266377449036, Discriminator Loss: 1.366645336151123\n",
      "Epoch [90/100], Generator Loss: 0.9619309902191162, Discriminator Loss: 1.1926465034484863\n"
     ]
    }
   ],
   "source": [
    "# Define the Generator and Discriminator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define GAN\n",
    "class GAN:\n",
    "    def __init__(self, generator, discriminator, criterion, optimizer_G, optimizer_D):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_G = optimizer_G\n",
    "        self.optimizer_D = optimizer_D\n",
    "\n",
    "    def train(self, dataloader, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (real_samples, _) in enumerate(dataloader):\n",
    "                # Train Discriminator\n",
    "                self.optimizer_D.zero_grad()\n",
    "                real_samples = real_samples.to(device)\n",
    "                real_labels = torch.ones(real_samples.size(0), 1).to(device)\n",
    "                fake_labels = torch.zeros(real_samples.size(0), 1).to(device)\n",
    "\n",
    "                # Train with real samples\n",
    "                real_output = self.discriminator(real_samples)\n",
    "                loss_real = self.criterion(real_output, real_labels)\n",
    "\n",
    "                # Train with fake samples\n",
    "                noise = torch.randn(real_samples.size(0), latent_size).to(device)\n",
    "                fake_samples = self.generator(noise)\n",
    "                fake_output = self.discriminator(fake_samples.detach())\n",
    "                loss_fake = self.criterion(fake_output, fake_labels)\n",
    "\n",
    "                # Update Discriminator\n",
    "                loss_D = loss_real + loss_fake\n",
    "                loss_D.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                # Train Generator\n",
    "                self.optimizer_G.zero_grad()\n",
    "                noise = torch.randn(real_samples.size(0), latent_size).to(device)\n",
    "                fake_samples = self.generator(noise)\n",
    "                output = self.discriminator(fake_samples)\n",
    "                loss_G = self.criterion(output, real_labels)\n",
    "\n",
    "                # Update Generator\n",
    "                loss_G.backward()\n",
    "                self.optimizer_G.step()\n",
    "\n",
    "            # Print Losses\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Generator Loss: {loss_G.item()}, Discriminator Loss: {loss_D.item()}\")\n",
    "\n",
    "# Parameters\n",
    "input_size = len(features)\n",
    "output_size = 1\n",
    "latent_size = 32\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "# Define DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize models, optimizers, and criterion\n",
    "generator = Generator(latent_size, input_size).to(device)\n",
    "discriminator = Discriminator(input_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "# Initialize GAN\n",
    "gan = GAN(generator, discriminator, criterion, optimizer_G, optimizer_D)\n",
    "\n",
    "# Train GAN\n",
    "gan.train(dataloader, num_epochs)\n",
    "\n",
    "# Generate synthetic data\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(len(data_files1), latent_size).to(device)\n",
    "    synthetic_samples = gan.generator(noise).cpu().numpy()\n",
    "\n",
    "# Convert synthetic data to DataFrame\n",
    "synthetic_df = pd.DataFrame(synthetic_samples, columns=features)\n",
    "\n",
    "# Inverse scaling \n",
    "synthetic_df[features] = scaler.inverse_transform(synthetic_df[features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df.to_csv(\"synthetic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method#2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mahin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This block is just to visualise the model\n",
    "\n",
    "from keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "Tx = 10  # Example value, replace with your actual value\n",
    "num_features = 5  # Example value, replace with your actual value\n",
    "\n",
    "inputs = Input(shape=(100,))\n",
    "x = Dense(128, use_bias=False)(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(64)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "outputs = Dense(Tx * num_features)(x)\n",
    "outputs = Reshape((Tx, num_features))(outputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mahin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mahin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mahin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1, Generator Loss: 1.046537160873413, Discriminator Loss: 1.5757927894592285\n",
      "Epoch 1, Batch 2, Generator Loss: 1.0721616744995117, Discriminator Loss: 1.6030009984970093\n",
      "Epoch 1, Batch 3, Generator Loss: 1.050204873085022, Discriminator Loss: 1.6003435850143433\n",
      "Epoch 1, Batch 4, Generator Loss: 1.0244303941726685, Discriminator Loss: 1.5911539793014526\n",
      "Epoch 1, Batch 5, Generator Loss: 1.0454626083374023, Discriminator Loss: 1.5842359066009521\n",
      "Epoch 1, Batch 6, Generator Loss: 1.0222517251968384, Discriminator Loss: 1.575073480606079\n",
      "Epoch 1, Batch 7, Generator Loss: 1.032480001449585, Discriminator Loss: 1.5817631483078003\n",
      "Epoch 1, Batch 8, Generator Loss: 1.0087206363677979, Discriminator Loss: 1.5236444473266602\n",
      "Epoch 1, Batch 9, Generator Loss: 1.0099802017211914, Discriminator Loss: 1.5752239227294922\n",
      "Epoch 1, Batch 10, Generator Loss: 1.0275976657867432, Discriminator Loss: 1.5761126279830933\n",
      "Epoch 1, Batch 11, Generator Loss: 1.0268385410308838, Discriminator Loss: 1.5783724784851074\n",
      "Epoch 1, Batch 12, Generator Loss: 1.0432186126708984, Discriminator Loss: 1.5624489784240723\n",
      "Epoch 1, Batch 13, Generator Loss: 1.0404900312423706, Discriminator Loss: 1.571184754371643\n",
      "Epoch 1, Batch 14, Generator Loss: 1.0191303491592407, Discriminator Loss: 1.5505907535552979\n",
      "Epoch 1, Batch 15, Generator Loss: 1.0182470083236694, Discriminator Loss: 1.5573601722717285\n",
      "Epoch 1, Batch 16, Generator Loss: 0.9902423620223999, Discriminator Loss: 1.5332757234573364\n",
      "Epoch 1, Batch 17, Generator Loss: 1.015805721282959, Discriminator Loss: 1.55112886428833\n",
      "Epoch 1, Batch 18, Generator Loss: 1.0056610107421875, Discriminator Loss: 1.4938626289367676\n",
      "Epoch 1, Batch 19, Generator Loss: 0.9918482899665833, Discriminator Loss: 1.5779507160186768\n",
      "Epoch 1, Batch 20, Generator Loss: 1.0106027126312256, Discriminator Loss: 1.548610806465149\n",
      "Epoch 1, Batch 21, Generator Loss: 1.003021478652954, Discriminator Loss: 1.5479393005371094\n",
      "Epoch 1, Batch 22, Generator Loss: 1.0008347034454346, Discriminator Loss: 1.5641065835952759\n",
      "Epoch 1, Batch 23, Generator Loss: 0.9913437366485596, Discriminator Loss: 1.5068193674087524\n",
      "Epoch 1, Batch 24, Generator Loss: 0.9956377148628235, Discriminator Loss: 1.5841313600540161\n",
      "Epoch 1, Batch 25, Generator Loss: 0.9930024147033691, Discriminator Loss: 1.5236375331878662\n",
      "Epoch 1, Batch 26, Generator Loss: 0.9942560791969299, Discriminator Loss: 1.5312950611114502\n",
      "Epoch 1, Batch 27, Generator Loss: 0.9768092036247253, Discriminator Loss: 1.5294225215911865\n",
      "Epoch 1, Batch 28, Generator Loss: 0.9863951802253723, Discriminator Loss: 1.5034115314483643\n",
      "Epoch 1, Batch 29, Generator Loss: 1.003982424736023, Discriminator Loss: 1.5450053215026855\n",
      "Epoch 1, Batch 30, Generator Loss: 0.9938915371894836, Discriminator Loss: 1.5361459255218506\n",
      "Epoch 1, Batch 31, Generator Loss: 0.9966091513633728, Discriminator Loss: 1.5207568407058716\n",
      "Epoch 1, Batch 32, Generator Loss: 0.9795952439308167, Discriminator Loss: 1.5148444175720215\n",
      "Epoch 1, Batch 33, Generator Loss: 0.9872910976409912, Discriminator Loss: 1.4928869009017944\n",
      "Epoch 1, Batch 34, Generator Loss: 0.9624931812286377, Discriminator Loss: 1.5179638862609863\n",
      "Epoch 1, Batch 35, Generator Loss: 0.9684842824935913, Discriminator Loss: 1.5043914318084717\n",
      "Epoch 1, Batch 36, Generator Loss: 0.9864233732223511, Discriminator Loss: 1.5006604194641113\n",
      "Epoch 1, Batch 37, Generator Loss: 0.9540729522705078, Discriminator Loss: 1.4846575260162354\n",
      "Epoch 1, Batch 38, Generator Loss: 0.9678289890289307, Discriminator Loss: 1.4655394554138184\n",
      "Epoch 1, Batch 39, Generator Loss: 0.9532564282417297, Discriminator Loss: 1.5189619064331055\n",
      "Epoch 1, Batch 40, Generator Loss: 0.9615636467933655, Discriminator Loss: 1.5001497268676758\n",
      "Epoch 1, Batch 41, Generator Loss: 0.9627976417541504, Discriminator Loss: 1.5048472881317139\n",
      "Epoch 1, Batch 42, Generator Loss: 0.950225293636322, Discriminator Loss: 1.5129611492156982\n",
      "Epoch 1, Batch 43, Generator Loss: 0.952849805355072, Discriminator Loss: 1.4875885248184204\n",
      "Epoch 1, Batch 44, Generator Loss: 0.9542924165725708, Discriminator Loss: 1.4832375049591064\n",
      "Epoch 1, Batch 45, Generator Loss: 0.9518831968307495, Discriminator Loss: 1.468538522720337\n",
      "Epoch 1, Batch 46, Generator Loss: 0.9535785913467407, Discriminator Loss: 1.4981813430786133\n",
      "Epoch 1, Batch 47, Generator Loss: 0.9512799978256226, Discriminator Loss: 1.4596753120422363\n",
      "Epoch 1, Batch 48, Generator Loss: 0.948494553565979, Discriminator Loss: 1.4657280445098877\n",
      "Epoch 1, Batch 49, Generator Loss: 0.9392996430397034, Discriminator Loss: 1.4659653902053833\n",
      "Epoch 1, Batch 50, Generator Loss: 0.9540857076644897, Discriminator Loss: 1.4509203433990479\n",
      "Epoch 1, Batch 51, Generator Loss: 0.9564304351806641, Discriminator Loss: 1.4786834716796875\n",
      "Epoch 1, Batch 52, Generator Loss: 0.9378629326820374, Discriminator Loss: 1.4473531246185303\n",
      "Epoch 1, Batch 53, Generator Loss: 0.9289013743400574, Discriminator Loss: 1.4730451107025146\n",
      "Epoch 1, Batch 54, Generator Loss: 0.9331676959991455, Discriminator Loss: 1.4602539539337158\n",
      "Epoch 1, Batch 55, Generator Loss: 0.9461930394172668, Discriminator Loss: 1.4518427848815918\n",
      "Epoch 1, Batch 56, Generator Loss: 0.9338415861129761, Discriminator Loss: 1.4941526651382446\n",
      "Epoch 1, Batch 57, Generator Loss: 0.9442455768585205, Discriminator Loss: 1.454693078994751\n",
      "Epoch 1, Batch 58, Generator Loss: 0.9241408109664917, Discriminator Loss: 1.4530141353607178\n",
      "Epoch 1, Batch 59, Generator Loss: 0.9208126068115234, Discriminator Loss: 1.4600999355316162\n",
      "Epoch 1, Batch 60, Generator Loss: 0.9159108400344849, Discriminator Loss: 1.4931285381317139\n",
      "Epoch 1, Batch 61, Generator Loss: 0.925801694393158, Discriminator Loss: 1.394141435623169\n",
      "Epoch 1, Batch 62, Generator Loss: 0.9238523244857788, Discriminator Loss: 1.4767178297042847\n",
      "Epoch 1, Batch 63, Generator Loss: 0.9414001107215881, Discriminator Loss: 1.444598913192749\n",
      "Epoch 1, Batch 64, Generator Loss: 0.9205986857414246, Discriminator Loss: 1.4546246528625488\n",
      "Epoch 1, Batch 65, Generator Loss: 0.9196391701698303, Discriminator Loss: 1.4457519054412842\n",
      "Epoch 1, Batch 66, Generator Loss: 0.912529706954956, Discriminator Loss: 1.4675744771957397\n",
      "Epoch 1, Batch 67, Generator Loss: 0.8919286727905273, Discriminator Loss: 1.4775786399841309\n",
      "Epoch 1, Batch 68, Generator Loss: 0.9071011543273926, Discriminator Loss: 1.4746752977371216\n",
      "Epoch 1, Batch 69, Generator Loss: 0.9242430925369263, Discriminator Loss: 1.43961501121521\n",
      "Epoch 1, Batch 70, Generator Loss: 0.9349192380905151, Discriminator Loss: 1.422925353050232\n",
      "Epoch 1, Batch 71, Generator Loss: 0.9147375822067261, Discriminator Loss: 1.4763246774673462\n",
      "Epoch 1, Batch 72, Generator Loss: 0.913116455078125, Discriminator Loss: 1.516251802444458\n",
      "Epoch 1, Batch 73, Generator Loss: 0.8910471200942993, Discriminator Loss: 1.4881095886230469\n",
      "Epoch 1, Batch 74, Generator Loss: 0.8986597657203674, Discriminator Loss: 1.47163724899292\n",
      "Epoch 1, Batch 75, Generator Loss: 0.8904848098754883, Discriminator Loss: 1.4666558504104614\n",
      "Epoch 1, Batch 76, Generator Loss: 0.898342490196228, Discriminator Loss: 1.4839379787445068\n",
      "Epoch 1, Batch 77, Generator Loss: 0.8870360255241394, Discriminator Loss: 1.5136604309082031\n",
      "Epoch 1, Batch 78, Generator Loss: 0.9037812352180481, Discriminator Loss: 1.4559041261672974\n",
      "Epoch 1, Batch 79, Generator Loss: 0.8875958919525146, Discriminator Loss: 1.4620287418365479\n",
      "Epoch 1, Batch 80, Generator Loss: 0.8770043849945068, Discriminator Loss: 1.4696801900863647\n",
      "Epoch 1, Batch 81, Generator Loss: 0.9023991823196411, Discriminator Loss: 1.4510345458984375\n",
      "Epoch 1, Batch 82, Generator Loss: 0.905615508556366, Discriminator Loss: 1.4245038032531738\n",
      "Epoch 1, Batch 83, Generator Loss: 0.8868406414985657, Discriminator Loss: 1.4352903366088867\n",
      "Epoch 1, Batch 84, Generator Loss: 0.8980710506439209, Discriminator Loss: 1.477771282196045\n",
      "Epoch 1, Batch 85, Generator Loss: 0.8918405175209045, Discriminator Loss: 1.4176970720291138\n",
      "Epoch 1, Batch 86, Generator Loss: 0.8980271816253662, Discriminator Loss: 1.4528415203094482\n",
      "Epoch 1, Batch 87, Generator Loss: 0.8917245864868164, Discriminator Loss: 1.4099067449569702\n",
      "Epoch 1, Batch 88, Generator Loss: 0.8764489889144897, Discriminator Loss: 1.425447940826416\n",
      "Epoch 1, Batch 89, Generator Loss: 0.8708696365356445, Discriminator Loss: 1.4657773971557617\n",
      "Epoch 1, Batch 90, Generator Loss: 0.8877061605453491, Discriminator Loss: 1.4668495655059814\n",
      "Epoch 1, Batch 91, Generator Loss: 0.8872060775756836, Discriminator Loss: 1.5015368461608887\n",
      "Epoch 2, Batch 1, Generator Loss: 0.8825706243515015, Discriminator Loss: 1.4394640922546387\n",
      "Epoch 2, Batch 2, Generator Loss: 0.8947906494140625, Discriminator Loss: 1.4433350563049316\n",
      "Epoch 2, Batch 3, Generator Loss: 0.8742107152938843, Discriminator Loss: 1.4403077363967896\n",
      "Epoch 2, Batch 4, Generator Loss: 0.879294753074646, Discriminator Loss: 1.4516818523406982\n",
      "Epoch 2, Batch 5, Generator Loss: 0.862531304359436, Discriminator Loss: 1.4313783645629883\n",
      "Epoch 2, Batch 6, Generator Loss: 0.8709425330162048, Discriminator Loss: 1.458630084991455\n",
      "Epoch 2, Batch 7, Generator Loss: 0.8694323301315308, Discriminator Loss: 1.437781572341919\n",
      "Epoch 2, Batch 8, Generator Loss: 0.8631902933120728, Discriminator Loss: 1.4414546489715576\n",
      "Epoch 2, Batch 9, Generator Loss: 0.870015025138855, Discriminator Loss: 1.4447925090789795\n",
      "Epoch 2, Batch 10, Generator Loss: 0.8779541850090027, Discriminator Loss: 1.417106032371521\n",
      "Epoch 2, Batch 11, Generator Loss: 0.8728439211845398, Discriminator Loss: 1.4369916915893555\n",
      "Epoch 2, Batch 12, Generator Loss: 0.8531942367553711, Discriminator Loss: 1.4543051719665527\n",
      "Epoch 2, Batch 13, Generator Loss: 0.8681532740592957, Discriminator Loss: 1.4292852878570557\n",
      "Epoch 2, Batch 14, Generator Loss: 0.8512448668479919, Discriminator Loss: 1.4395183324813843\n",
      "Epoch 2, Batch 15, Generator Loss: 0.8779831528663635, Discriminator Loss: 1.4234068393707275\n",
      "Epoch 2, Batch 16, Generator Loss: 0.8565638065338135, Discriminator Loss: 1.436847448348999\n",
      "Epoch 2, Batch 17, Generator Loss: 0.8482379913330078, Discriminator Loss: 1.4543921947479248\n",
      "Epoch 2, Batch 18, Generator Loss: 0.8457627296447754, Discriminator Loss: 1.3881653547286987\n",
      "Epoch 2, Batch 19, Generator Loss: 0.8769737482070923, Discriminator Loss: 1.4623136520385742\n",
      "Epoch 2, Batch 20, Generator Loss: 0.84394371509552, Discriminator Loss: 1.4032208919525146\n",
      "Epoch 2, Batch 21, Generator Loss: 0.8560595512390137, Discriminator Loss: 1.4347457885742188\n",
      "Epoch 2, Batch 22, Generator Loss: 0.8574668169021606, Discriminator Loss: 1.4447660446166992\n",
      "Epoch 2, Batch 23, Generator Loss: 0.8522492051124573, Discriminator Loss: 1.4289216995239258\n",
      "Epoch 2, Batch 24, Generator Loss: 0.8402657508850098, Discriminator Loss: 1.4515235424041748\n",
      "Epoch 2, Batch 25, Generator Loss: 0.8407881259918213, Discriminator Loss: 1.4283511638641357\n",
      "Epoch 2, Batch 26, Generator Loss: 0.8565313220024109, Discriminator Loss: 1.4506275653839111\n",
      "Epoch 2, Batch 27, Generator Loss: 0.8458241820335388, Discriminator Loss: 1.4420068264007568\n",
      "Epoch 2, Batch 28, Generator Loss: 0.8522765636444092, Discriminator Loss: 1.441164255142212\n",
      "Epoch 2, Batch 29, Generator Loss: 0.8435410857200623, Discriminator Loss: 1.4380851984024048\n",
      "Epoch 2, Batch 30, Generator Loss: 0.8494017124176025, Discriminator Loss: 1.4412750005722046\n",
      "Epoch 2, Batch 31, Generator Loss: 0.8423351049423218, Discriminator Loss: 1.4365426301956177\n",
      "Epoch 2, Batch 32, Generator Loss: 0.8390501737594604, Discriminator Loss: 1.4516879320144653\n",
      "Epoch 2, Batch 33, Generator Loss: 0.846019983291626, Discriminator Loss: 1.4112520217895508\n",
      "Epoch 2, Batch 34, Generator Loss: 0.8427308797836304, Discriminator Loss: 1.4432927370071411\n",
      "Epoch 2, Batch 35, Generator Loss: 0.847023069858551, Discriminator Loss: 1.4088785648345947\n",
      "Epoch 2, Batch 36, Generator Loss: 0.844862699508667, Discriminator Loss: 1.4175729751586914\n",
      "Epoch 2, Batch 37, Generator Loss: 0.8482235670089722, Discriminator Loss: 1.4204351902008057\n",
      "Epoch 2, Batch 38, Generator Loss: 0.8369060158729553, Discriminator Loss: 1.3824796676635742\n",
      "Epoch 2, Batch 39, Generator Loss: 0.8386819362640381, Discriminator Loss: 1.4315953254699707\n",
      "Epoch 2, Batch 40, Generator Loss: 0.8226430416107178, Discriminator Loss: 1.4409617185592651\n",
      "Epoch 2, Batch 41, Generator Loss: 0.833583652973175, Discriminator Loss: 1.443147897720337\n",
      "Epoch 2, Batch 42, Generator Loss: 0.845496654510498, Discriminator Loss: 1.438987135887146\n",
      "Epoch 2, Batch 43, Generator Loss: 0.8314957618713379, Discriminator Loss: 1.4336425065994263\n",
      "Epoch 2, Batch 44, Generator Loss: 0.8296419382095337, Discriminator Loss: 1.4088214635849\n",
      "Epoch 2, Batch 45, Generator Loss: 0.8262829780578613, Discriminator Loss: 1.3940991163253784\n",
      "Epoch 2, Batch 46, Generator Loss: 0.8219171762466431, Discriminator Loss: 1.417731523513794\n",
      "Epoch 2, Batch 47, Generator Loss: 0.8204231262207031, Discriminator Loss: 1.3993467092514038\n",
      "Epoch 2, Batch 48, Generator Loss: 0.8264153003692627, Discriminator Loss: 1.3953847885131836\n",
      "Epoch 2, Batch 49, Generator Loss: 0.8171296119689941, Discriminator Loss: 1.4137349128723145\n",
      "Epoch 2, Batch 50, Generator Loss: 0.8271870017051697, Discriminator Loss: 1.3643474578857422\n",
      "Epoch 2, Batch 51, Generator Loss: 0.8278415203094482, Discriminator Loss: 1.4344396591186523\n",
      "Epoch 2, Batch 52, Generator Loss: 0.8227980136871338, Discriminator Loss: 1.3794071674346924\n",
      "Epoch 2, Batch 53, Generator Loss: 0.8337156772613525, Discriminator Loss: 1.3936749696731567\n",
      "Epoch 2, Batch 54, Generator Loss: 0.8205585479736328, Discriminator Loss: 1.4009132385253906\n",
      "Epoch 2, Batch 55, Generator Loss: 0.8097054958343506, Discriminator Loss: 1.3757426738739014\n",
      "Epoch 2, Batch 56, Generator Loss: 0.8205156326293945, Discriminator Loss: 1.4418015480041504\n",
      "Epoch 2, Batch 57, Generator Loss: 0.8154455423355103, Discriminator Loss: 1.4036964178085327\n",
      "Epoch 2, Batch 58, Generator Loss: 0.8253268003463745, Discriminator Loss: 1.365553617477417\n",
      "Epoch 2, Batch 59, Generator Loss: 0.8210166692733765, Discriminator Loss: 1.3938013315200806\n",
      "Epoch 2, Batch 60, Generator Loss: 0.8120417594909668, Discriminator Loss: 1.4292489290237427\n",
      "Epoch 2, Batch 61, Generator Loss: 0.8122827410697937, Discriminator Loss: 1.3528566360473633\n",
      "Epoch 2, Batch 62, Generator Loss: 0.8191924095153809, Discriminator Loss: 1.408098578453064\n",
      "Epoch 2, Batch 63, Generator Loss: 0.8137398362159729, Discriminator Loss: 1.3872202634811401\n",
      "Epoch 2, Batch 64, Generator Loss: 0.8314023017883301, Discriminator Loss: 1.403108835220337\n",
      "Epoch 2, Batch 65, Generator Loss: 0.8101904988288879, Discriminator Loss: 1.3809325695037842\n",
      "Epoch 2, Batch 66, Generator Loss: 0.8189243674278259, Discriminator Loss: 1.4215991497039795\n",
      "Epoch 2, Batch 67, Generator Loss: 0.804084062576294, Discriminator Loss: 1.4127041101455688\n",
      "Epoch 2, Batch 68, Generator Loss: 0.8097457885742188, Discriminator Loss: 1.427121877670288\n",
      "Epoch 2, Batch 69, Generator Loss: 0.809307873249054, Discriminator Loss: 1.3856091499328613\n",
      "Epoch 2, Batch 70, Generator Loss: 0.812140703201294, Discriminator Loss: 1.3669203519821167\n",
      "Epoch 2, Batch 71, Generator Loss: 0.8084890842437744, Discriminator Loss: 1.4105099439620972\n",
      "Epoch 2, Batch 72, Generator Loss: 0.809317946434021, Discriminator Loss: 1.4619433879852295\n",
      "Epoch 2, Batch 73, Generator Loss: 0.8187583088874817, Discriminator Loss: 1.4442247152328491\n",
      "Epoch 2, Batch 74, Generator Loss: 0.8041315078735352, Discriminator Loss: 1.446014642715454\n",
      "Epoch 2, Batch 75, Generator Loss: 0.8144168257713318, Discriminator Loss: 1.4083126783370972\n",
      "Epoch 2, Batch 76, Generator Loss: 0.8024122714996338, Discriminator Loss: 1.4306704998016357\n",
      "Epoch 2, Batch 77, Generator Loss: 0.8068925738334656, Discriminator Loss: 1.4420613050460815\n",
      "Epoch 2, Batch 78, Generator Loss: 0.8057339191436768, Discriminator Loss: 1.4101500511169434\n",
      "Epoch 2, Batch 79, Generator Loss: 0.7973202466964722, Discriminator Loss: 1.4172587394714355\n",
      "Epoch 2, Batch 80, Generator Loss: 0.8002471923828125, Discriminator Loss: 1.4088212251663208\n",
      "Epoch 2, Batch 81, Generator Loss: 0.7923517823219299, Discriminator Loss: 1.4046928882598877\n",
      "Epoch 2, Batch 82, Generator Loss: 0.7987256050109863, Discriminator Loss: 1.380204200744629\n",
      "Epoch 2, Batch 83, Generator Loss: 0.8149760365486145, Discriminator Loss: 1.3890421390533447\n",
      "Epoch 2, Batch 84, Generator Loss: 0.7991892099380493, Discriminator Loss: 1.4414942264556885\n",
      "Epoch 2, Batch 85, Generator Loss: 0.8036119937896729, Discriminator Loss: 1.3800655603408813\n",
      "Epoch 2, Batch 86, Generator Loss: 0.8031752109527588, Discriminator Loss: 1.4183059930801392\n",
      "Epoch 2, Batch 87, Generator Loss: 0.8091393709182739, Discriminator Loss: 1.3642923831939697\n",
      "Epoch 2, Batch 88, Generator Loss: 0.8031140565872192, Discriminator Loss: 1.3740780353546143\n",
      "Epoch 2, Batch 89, Generator Loss: 0.8038772344589233, Discriminator Loss: 1.4120564460754395\n",
      "Epoch 2, Batch 90, Generator Loss: 0.7906358242034912, Discriminator Loss: 1.4209550619125366\n",
      "Epoch 2, Batch 91, Generator Loss: 0.7887082099914551, Discriminator Loss: 1.4567193984985352\n",
      "Epoch 3, Batch 1, Generator Loss: 0.7944739460945129, Discriminator Loss: 1.4011645317077637\n",
      "Epoch 3, Batch 2, Generator Loss: 0.7818410396575928, Discriminator Loss: 1.4171502590179443\n",
      "Epoch 3, Batch 3, Generator Loss: 0.7872600555419922, Discriminator Loss: 1.3860722780227661\n",
      "Epoch 3, Batch 4, Generator Loss: 0.7956210970878601, Discriminator Loss: 1.403657078742981\n",
      "Epoch 3, Batch 5, Generator Loss: 0.7875185012817383, Discriminator Loss: 1.3946917057037354\n",
      "Epoch 3, Batch 6, Generator Loss: 0.7941707372665405, Discriminator Loss: 1.4035779237747192\n",
      "Epoch 3, Batch 7, Generator Loss: 0.7919069528579712, Discriminator Loss: 1.3968733549118042\n",
      "Epoch 3, Batch 8, Generator Loss: 0.7834961414337158, Discriminator Loss: 1.4003348350524902\n",
      "Epoch 3, Batch 9, Generator Loss: 0.7864111065864563, Discriminator Loss: 1.409000277519226\n",
      "Epoch 3, Batch 10, Generator Loss: 0.8090948462486267, Discriminator Loss: 1.3726099729537964\n",
      "Epoch 3, Batch 11, Generator Loss: 0.7887808084487915, Discriminator Loss: 1.4032514095306396\n",
      "Epoch 3, Batch 12, Generator Loss: 0.797446608543396, Discriminator Loss: 1.4151229858398438\n",
      "Epoch 3, Batch 13, Generator Loss: 0.7833964824676514, Discriminator Loss: 1.3923401832580566\n",
      "Epoch 3, Batch 14, Generator Loss: 0.7877599000930786, Discriminator Loss: 1.3959013223648071\n",
      "Epoch 3, Batch 15, Generator Loss: 0.7857756018638611, Discriminator Loss: 1.39694344997406\n",
      "Epoch 3, Batch 16, Generator Loss: 0.7872039675712585, Discriminator Loss: 1.3935892581939697\n",
      "Epoch 3, Batch 17, Generator Loss: 0.7773079872131348, Discriminator Loss: 1.4138438701629639\n",
      "Epoch 3, Batch 18, Generator Loss: 0.7809793949127197, Discriminator Loss: 1.3499436378479004\n",
      "Epoch 3, Batch 19, Generator Loss: 0.7734509706497192, Discriminator Loss: 1.4329019784927368\n",
      "Epoch 3, Batch 20, Generator Loss: 0.7738624811172485, Discriminator Loss: 1.3697011470794678\n",
      "Epoch 3, Batch 21, Generator Loss: 0.7633084058761597, Discriminator Loss: 1.4074715375900269\n",
      "Epoch 3, Batch 22, Generator Loss: 0.7761369943618774, Discriminator Loss: 1.4068807363510132\n",
      "Epoch 3, Batch 23, Generator Loss: 0.7831310033798218, Discriminator Loss: 1.4075746536254883\n",
      "Epoch 3, Batch 24, Generator Loss: 0.7770570516586304, Discriminator Loss: 1.4092220067977905\n",
      "Epoch 3, Batch 25, Generator Loss: 0.7749762535095215, Discriminator Loss: 1.4059584140777588\n",
      "Epoch 3, Batch 26, Generator Loss: 0.7762852907180786, Discriminator Loss: 1.4262971878051758\n",
      "Epoch 3, Batch 27, Generator Loss: 0.7928009033203125, Discriminator Loss: 1.4013017416000366\n",
      "Epoch 3, Batch 28, Generator Loss: 0.7698929309844971, Discriminator Loss: 1.3919497728347778\n",
      "Epoch 3, Batch 29, Generator Loss: 0.7678657174110413, Discriminator Loss: 1.389352798461914\n",
      "Epoch 3, Batch 30, Generator Loss: 0.783990740776062, Discriminator Loss: 1.4177336692810059\n",
      "Epoch 3, Batch 31, Generator Loss: 0.769228458404541, Discriminator Loss: 1.401548147201538\n",
      "Epoch 3, Batch 32, Generator Loss: 0.7806868553161621, Discriminator Loss: 1.4078738689422607\n",
      "Epoch 3, Batch 33, Generator Loss: 0.7749413251876831, Discriminator Loss: 1.3883521556854248\n",
      "Epoch 3, Batch 34, Generator Loss: 0.7775894999504089, Discriminator Loss: 1.4122165441513062\n",
      "Epoch 3, Batch 35, Generator Loss: 0.7831750512123108, Discriminator Loss: 1.3632421493530273\n",
      "Epoch 3, Batch 36, Generator Loss: 0.7737642526626587, Discriminator Loss: 1.3805795907974243\n",
      "Epoch 3, Batch 37, Generator Loss: 0.7725890278816223, Discriminator Loss: 1.3943445682525635\n",
      "Epoch 3, Batch 38, Generator Loss: 0.7720320224761963, Discriminator Loss: 1.3641233444213867\n",
      "Epoch 3, Batch 39, Generator Loss: 0.7616323232650757, Discriminator Loss: 1.4196749925613403\n",
      "Epoch 3, Batch 40, Generator Loss: 0.7797765731811523, Discriminator Loss: 1.4014339447021484\n",
      "Epoch 3, Batch 41, Generator Loss: 0.7678479552268982, Discriminator Loss: 1.4073584079742432\n",
      "Epoch 3, Batch 42, Generator Loss: 0.7605665922164917, Discriminator Loss: 1.4191380739212036\n",
      "Epoch 3, Batch 43, Generator Loss: 0.7639362812042236, Discriminator Loss: 1.4144134521484375\n",
      "Epoch 3, Batch 44, Generator Loss: 0.7672666311264038, Discriminator Loss: 1.3894340991973877\n",
      "Epoch 3, Batch 45, Generator Loss: 0.7676677107810974, Discriminator Loss: 1.3539507389068604\n",
      "Epoch 3, Batch 46, Generator Loss: 0.7721734046936035, Discriminator Loss: 1.3694777488708496\n",
      "Epoch 3, Batch 47, Generator Loss: 0.7499579191207886, Discriminator Loss: 1.3758721351623535\n",
      "Epoch 3, Batch 48, Generator Loss: 0.7658138275146484, Discriminator Loss: 1.3869962692260742\n",
      "Epoch 3, Batch 49, Generator Loss: 0.7747654914855957, Discriminator Loss: 1.3757133483886719\n",
      "Epoch 3, Batch 50, Generator Loss: 0.7688759565353394, Discriminator Loss: 1.3324445486068726\n",
      "Epoch 3, Batch 51, Generator Loss: 0.767376184463501, Discriminator Loss: 1.4050631523132324\n",
      "Epoch 3, Batch 52, Generator Loss: 0.7606724500656128, Discriminator Loss: 1.3456697463989258\n",
      "Epoch 3, Batch 53, Generator Loss: 0.7524158358573914, Discriminator Loss: 1.3810473680496216\n",
      "Epoch 3, Batch 54, Generator Loss: 0.7822322249412537, Discriminator Loss: 1.3751931190490723\n",
      "Epoch 3, Batch 55, Generator Loss: 0.7602111101150513, Discriminator Loss: 1.3401811122894287\n",
      "Epoch 3, Batch 56, Generator Loss: 0.7685490846633911, Discriminator Loss: 1.4070184230804443\n",
      "Epoch 3, Batch 57, Generator Loss: 0.765181839466095, Discriminator Loss: 1.3811298608779907\n",
      "Epoch 3, Batch 58, Generator Loss: 0.7504913806915283, Discriminator Loss: 1.3507366180419922\n",
      "Epoch 3, Batch 59, Generator Loss: 0.765779972076416, Discriminator Loss: 1.3595030307769775\n",
      "Epoch 3, Batch 60, Generator Loss: 0.758560061454773, Discriminator Loss: 1.404212474822998\n",
      "Epoch 3, Batch 61, Generator Loss: 0.7556823492050171, Discriminator Loss: 1.3370823860168457\n",
      "Epoch 3, Batch 62, Generator Loss: 0.7645330429077148, Discriminator Loss: 1.3666326999664307\n",
      "Epoch 3, Batch 63, Generator Loss: 0.7651877403259277, Discriminator Loss: 1.3510217666625977\n",
      "Epoch 3, Batch 64, Generator Loss: 0.7602317333221436, Discriminator Loss: 1.3886847496032715\n",
      "Epoch 3, Batch 65, Generator Loss: 0.7599616050720215, Discriminator Loss: 1.3581583499908447\n",
      "Epoch 3, Batch 66, Generator Loss: 0.7702974081039429, Discriminator Loss: 1.3939861059188843\n",
      "Epoch 3, Batch 67, Generator Loss: 0.7704223394393921, Discriminator Loss: 1.3810169696807861\n",
      "Epoch 3, Batch 68, Generator Loss: 0.7525473833084106, Discriminator Loss: 1.408799171447754\n",
      "Epoch 3, Batch 69, Generator Loss: 0.7561665773391724, Discriminator Loss: 1.3655050992965698\n",
      "Epoch 3, Batch 70, Generator Loss: 0.7555676102638245, Discriminator Loss: 1.3423194885253906\n",
      "Epoch 3, Batch 71, Generator Loss: 0.7588018178939819, Discriminator Loss: 1.376791000366211\n",
      "Epoch 3, Batch 72, Generator Loss: 0.7486461997032166, Discriminator Loss: 1.4379892349243164\n",
      "Epoch 3, Batch 73, Generator Loss: 0.7441565990447998, Discriminator Loss: 1.4234323501586914\n",
      "Epoch 3, Batch 74, Generator Loss: 0.7514526844024658, Discriminator Loss: 1.4237496852874756\n",
      "Epoch 3, Batch 75, Generator Loss: 0.7663042545318604, Discriminator Loss: 1.3666871786117554\n",
      "Epoch 3, Batch 76, Generator Loss: 0.7535852789878845, Discriminator Loss: 1.4102997779846191\n",
      "Epoch 3, Batch 77, Generator Loss: 0.7659417390823364, Discriminator Loss: 1.4301124811172485\n",
      "Epoch 3, Batch 78, Generator Loss: 0.7627450227737427, Discriminator Loss: 1.3946666717529297\n",
      "Epoch 3, Batch 79, Generator Loss: 0.766659140586853, Discriminator Loss: 1.3909543752670288\n",
      "Epoch 3, Batch 80, Generator Loss: 0.7599049806594849, Discriminator Loss: 1.3857026100158691\n",
      "Epoch 3, Batch 81, Generator Loss: 0.7666172981262207, Discriminator Loss: 1.3828051090240479\n",
      "Epoch 3, Batch 82, Generator Loss: 0.7566332817077637, Discriminator Loss: 1.352980613708496\n",
      "Epoch 3, Batch 83, Generator Loss: 0.7405763864517212, Discriminator Loss: 1.3885269165039062\n",
      "Epoch 3, Batch 84, Generator Loss: 0.7590236663818359, Discriminator Loss: 1.4122593402862549\n",
      "Epoch 3, Batch 85, Generator Loss: 0.7472704648971558, Discriminator Loss: 1.3640930652618408\n",
      "Epoch 3, Batch 86, Generator Loss: 0.7549402117729187, Discriminator Loss: 1.400284767150879\n",
      "Epoch 3, Batch 87, Generator Loss: 0.7607172727584839, Discriminator Loss: 1.338911771774292\n",
      "Epoch 3, Batch 88, Generator Loss: 0.751909613609314, Discriminator Loss: 1.3539320230484009\n",
      "Epoch 3, Batch 89, Generator Loss: 0.7530677914619446, Discriminator Loss: 1.4016379117965698\n",
      "Epoch 3, Batch 90, Generator Loss: 0.7548670172691345, Discriminator Loss: 1.3747332096099854\n",
      "Epoch 3, Batch 91, Generator Loss: 0.7496355772018433, Discriminator Loss: 1.4231128692626953\n",
      "Epoch 4, Batch 1, Generator Loss: 0.7580864429473877, Discriminator Loss: 1.37453031539917\n",
      "Epoch 4, Batch 2, Generator Loss: 0.7510117888450623, Discriminator Loss: 1.3839025497436523\n",
      "Epoch 4, Batch 3, Generator Loss: 0.7474794387817383, Discriminator Loss: 1.3616019487380981\n",
      "Epoch 4, Batch 4, Generator Loss: 0.7405591011047363, Discriminator Loss: 1.3933370113372803\n",
      "Epoch 4, Batch 5, Generator Loss: 0.7495377063751221, Discriminator Loss: 1.3737313747406006\n",
      "Epoch 4, Batch 6, Generator Loss: 0.7565382719039917, Discriminator Loss: 1.3819222450256348\n",
      "Epoch 4, Batch 7, Generator Loss: 0.7560940384864807, Discriminator Loss: 1.364096760749817\n",
      "Epoch 4, Batch 8, Generator Loss: 0.7353023290634155, Discriminator Loss: 1.3901607990264893\n",
      "Epoch 4, Batch 9, Generator Loss: 0.7493270635604858, Discriminator Loss: 1.3848224878311157\n",
      "Epoch 4, Batch 10, Generator Loss: 0.7474441528320312, Discriminator Loss: 1.3559823036193848\n",
      "Epoch 4, Batch 11, Generator Loss: 0.7509702444076538, Discriminator Loss: 1.3767203092575073\n",
      "Epoch 4, Batch 12, Generator Loss: 0.7463270425796509, Discriminator Loss: 1.403189778327942\n",
      "Epoch 4, Batch 13, Generator Loss: 0.7373353838920593, Discriminator Loss: 1.3774223327636719\n",
      "Epoch 4, Batch 14, Generator Loss: 0.760260820388794, Discriminator Loss: 1.3789252042770386\n",
      "Epoch 4, Batch 15, Generator Loss: 0.7414164543151855, Discriminator Loss: 1.3898332118988037\n",
      "Epoch 4, Batch 16, Generator Loss: 0.7406758069992065, Discriminator Loss: 1.3798646926879883\n",
      "Epoch 4, Batch 17, Generator Loss: 0.7474278211593628, Discriminator Loss: 1.3941724300384521\n",
      "Epoch 4, Batch 18, Generator Loss: 0.75795578956604, Discriminator Loss: 1.3252500295639038\n",
      "Epoch 4, Batch 19, Generator Loss: 0.749339759349823, Discriminator Loss: 1.4037909507751465\n",
      "Epoch 4, Batch 20, Generator Loss: 0.7551153898239136, Discriminator Loss: 1.3299890756607056\n",
      "Epoch 4, Batch 21, Generator Loss: 0.7490233182907104, Discriminator Loss: 1.3689393997192383\n",
      "Epoch 4, Batch 22, Generator Loss: 0.731282114982605, Discriminator Loss: 1.4134297370910645\n",
      "Epoch 4, Batch 23, Generator Loss: 0.7519664764404297, Discriminator Loss: 1.3912131786346436\n",
      "Epoch 4, Batch 24, Generator Loss: 0.7417196035385132, Discriminator Loss: 1.3857707977294922\n",
      "Epoch 4, Batch 25, Generator Loss: 0.7354632019996643, Discriminator Loss: 1.3834534883499146\n",
      "Epoch 4, Batch 26, Generator Loss: 0.7463011741638184, Discriminator Loss: 1.4130544662475586\n",
      "Epoch 4, Batch 27, Generator Loss: 0.7351638078689575, Discriminator Loss: 1.4023597240447998\n",
      "Epoch 4, Batch 28, Generator Loss: 0.7339471578598022, Discriminator Loss: 1.3801274299621582\n",
      "Epoch 4, Batch 29, Generator Loss: 0.7410720586776733, Discriminator Loss: 1.3686741590499878\n",
      "Epoch 4, Batch 30, Generator Loss: 0.7430160045623779, Discriminator Loss: 1.4000741243362427\n",
      "Epoch 4, Batch 31, Generator Loss: 0.7409350872039795, Discriminator Loss: 1.3766425848007202\n",
      "Epoch 4, Batch 32, Generator Loss: 0.7310516238212585, Discriminator Loss: 1.4029000997543335\n",
      "Epoch 4, Batch 33, Generator Loss: 0.7487177848815918, Discriminator Loss: 1.3731307983398438\n",
      "Epoch 4, Batch 34, Generator Loss: 0.7316268682479858, Discriminator Loss: 1.4067493677139282\n",
      "Epoch 4, Batch 35, Generator Loss: 0.7452434301376343, Discriminator Loss: 1.3576463460922241\n",
      "Epoch 4, Batch 36, Generator Loss: 0.7492889165878296, Discriminator Loss: 1.3571150302886963\n",
      "Epoch 4, Batch 37, Generator Loss: 0.7531546354293823, Discriminator Loss: 1.3753032684326172\n",
      "Epoch 4, Batch 38, Generator Loss: 0.7426202893257141, Discriminator Loss: 1.3418943881988525\n",
      "Epoch 4, Batch 39, Generator Loss: 0.7386773824691772, Discriminator Loss: 1.3999946117401123\n",
      "Epoch 4, Batch 40, Generator Loss: 0.7364605665206909, Discriminator Loss: 1.39573073387146\n",
      "Epoch 4, Batch 41, Generator Loss: 0.7301760911941528, Discriminator Loss: 1.401394009590149\n",
      "Epoch 4, Batch 42, Generator Loss: 0.7398075461387634, Discriminator Loss: 1.3871188163757324\n",
      "Epoch 4, Batch 43, Generator Loss: 0.7457109689712524, Discriminator Loss: 1.3957599401474\n",
      "Epoch 4, Batch 44, Generator Loss: 0.7435005903244019, Discriminator Loss: 1.361290454864502\n",
      "Epoch 4, Batch 45, Generator Loss: 0.7330794930458069, Discriminator Loss: 1.343775749206543\n",
      "Epoch 4, Batch 46, Generator Loss: 0.745222806930542, Discriminator Loss: 1.3362374305725098\n",
      "Epoch 4, Batch 47, Generator Loss: 0.7449479103088379, Discriminator Loss: 1.3450608253479004\n",
      "Epoch 4, Batch 48, Generator Loss: 0.7344489097595215, Discriminator Loss: 1.37418532371521\n",
      "Epoch 4, Batch 49, Generator Loss: 0.7149394750595093, Discriminator Loss: 1.3724205493927002\n",
      "Epoch 4, Batch 50, Generator Loss: 0.744956374168396, Discriminator Loss: 1.3153434991836548\n",
      "Epoch 4, Batch 51, Generator Loss: 0.7551688551902771, Discriminator Loss: 1.395014762878418\n",
      "Epoch 4, Batch 52, Generator Loss: 0.7394653558731079, Discriminator Loss: 1.3225030899047852\n",
      "Epoch 4, Batch 53, Generator Loss: 0.7405688762664795, Discriminator Loss: 1.3603711128234863\n",
      "Epoch 4, Batch 54, Generator Loss: 0.7332829833030701, Discriminator Loss: 1.3820348978042603\n",
      "Epoch 4, Batch 55, Generator Loss: 0.7290450930595398, Discriminator Loss: 1.3263278007507324\n",
      "Epoch 4, Batch 56, Generator Loss: 0.7386988997459412, Discriminator Loss: 1.3992031812667847\n",
      "Epoch 4, Batch 57, Generator Loss: 0.740235447883606, Discriminator Loss: 1.3536124229431152\n",
      "Epoch 4, Batch 58, Generator Loss: 0.7239472270011902, Discriminator Loss: 1.3423638343811035\n",
      "Epoch 4, Batch 59, Generator Loss: 0.7305961847305298, Discriminator Loss: 1.3421220779418945\n",
      "Epoch 4, Batch 60, Generator Loss: 0.7277581691741943, Discriminator Loss: 1.3945865631103516\n",
      "Epoch 4, Batch 61, Generator Loss: 0.7358826398849487, Discriminator Loss: 1.3229856491088867\n",
      "Epoch 4, Batch 62, Generator Loss: 0.7286632657051086, Discriminator Loss: 1.3559417724609375\n",
      "Epoch 4, Batch 63, Generator Loss: 0.735268771648407, Discriminator Loss: 1.3474500179290771\n",
      "Epoch 4, Batch 64, Generator Loss: 0.7158647775650024, Discriminator Loss: 1.3969721794128418\n",
      "Epoch 4, Batch 65, Generator Loss: 0.730109691619873, Discriminator Loss: 1.335221290588379\n",
      "Epoch 4, Batch 66, Generator Loss: 0.7259904146194458, Discriminator Loss: 1.4013657569885254\n",
      "Epoch 4, Batch 67, Generator Loss: 0.7449122667312622, Discriminator Loss: 1.3693435192108154\n",
      "Epoch 4, Batch 68, Generator Loss: 0.7334982752799988, Discriminator Loss: 1.3925306797027588\n",
      "Epoch 4, Batch 69, Generator Loss: 0.7477025389671326, Discriminator Loss: 1.3372050523757935\n",
      "Epoch 4, Batch 70, Generator Loss: 0.7434589862823486, Discriminator Loss: 1.3109896183013916\n",
      "Epoch 4, Batch 71, Generator Loss: 0.7290079593658447, Discriminator Loss: 1.3609635829925537\n",
      "Epoch 4, Batch 72, Generator Loss: 0.7328383922576904, Discriminator Loss: 1.4203851222991943\n",
      "Epoch 4, Batch 73, Generator Loss: 0.7374094724655151, Discriminator Loss: 1.4127039909362793\n",
      "Epoch 4, Batch 74, Generator Loss: 0.7445969581604004, Discriminator Loss: 1.4078905582427979\n",
      "Epoch 4, Batch 75, Generator Loss: 0.7324286699295044, Discriminator Loss: 1.3589625358581543\n",
      "Epoch 4, Batch 76, Generator Loss: 0.7334359884262085, Discriminator Loss: 1.3953630924224854\n",
      "Epoch 4, Batch 77, Generator Loss: 0.74277263879776, Discriminator Loss: 1.4139012098312378\n",
      "Epoch 4, Batch 78, Generator Loss: 0.7516815066337585, Discriminator Loss: 1.3811886310577393\n",
      "Epoch 4, Batch 79, Generator Loss: 0.7585230469703674, Discriminator Loss: 1.378749132156372\n",
      "Epoch 4, Batch 80, Generator Loss: 0.7261083722114563, Discriminator Loss: 1.3933013677597046\n",
      "Epoch 4, Batch 81, Generator Loss: 0.7434951066970825, Discriminator Loss: 1.3771193027496338\n",
      "Epoch 4, Batch 82, Generator Loss: 0.7278132438659668, Discriminator Loss: 1.3387055397033691\n",
      "Epoch 4, Batch 83, Generator Loss: 0.7243664264678955, Discriminator Loss: 1.379677414894104\n",
      "Epoch 4, Batch 84, Generator Loss: 0.7308176159858704, Discriminator Loss: 1.4077980518341064\n",
      "Epoch 4, Batch 85, Generator Loss: 0.7293553352355957, Discriminator Loss: 1.343719720840454\n",
      "Epoch 4, Batch 86, Generator Loss: 0.7239843606948853, Discriminator Loss: 1.4110264778137207\n",
      "Epoch 4, Batch 87, Generator Loss: 0.7378972768783569, Discriminator Loss: 1.3281878232955933\n",
      "Epoch 4, Batch 88, Generator Loss: 0.7390340566635132, Discriminator Loss: 1.3374171257019043\n",
      "Epoch 4, Batch 89, Generator Loss: 0.7287951707839966, Discriminator Loss: 1.3911771774291992\n",
      "Epoch 4, Batch 90, Generator Loss: 0.7288216352462769, Discriminator Loss: 1.364522933959961\n",
      "Epoch 4, Batch 91, Generator Loss: 0.7399051189422607, Discriminator Loss: 1.407446265220642\n",
      "Epoch 5, Batch 1, Generator Loss: 0.7223094701766968, Discriminator Loss: 1.37534499168396\n",
      "Epoch 5, Batch 2, Generator Loss: 0.733500599861145, Discriminator Loss: 1.3717269897460938\n",
      "Epoch 5, Batch 3, Generator Loss: 0.7262104153633118, Discriminator Loss: 1.348567008972168\n",
      "Epoch 5, Batch 4, Generator Loss: 0.7251468896865845, Discriminator Loss: 1.3806614875793457\n",
      "Epoch 5, Batch 5, Generator Loss: 0.7400254011154175, Discriminator Loss: 1.362483024597168\n",
      "Epoch 5, Batch 6, Generator Loss: 0.7268378138542175, Discriminator Loss: 1.382397174835205\n",
      "Epoch 5, Batch 7, Generator Loss: 0.743493914604187, Discriminator Loss: 1.3589982986450195\n",
      "Epoch 5, Batch 8, Generator Loss: 0.7191194295883179, Discriminator Loss: 1.3732054233551025\n",
      "Epoch 5, Batch 9, Generator Loss: 0.7386704683303833, Discriminator Loss: 1.361607313156128\n",
      "Epoch 5, Batch 10, Generator Loss: 0.721039354801178, Discriminator Loss: 1.3527321815490723\n",
      "Epoch 5, Batch 11, Generator Loss: 0.721497654914856, Discriminator Loss: 1.3765283823013306\n",
      "Epoch 5, Batch 12, Generator Loss: 0.7260923981666565, Discriminator Loss: 1.3893238306045532\n",
      "Epoch 5, Batch 13, Generator Loss: 0.7366962432861328, Discriminator Loss: 1.3493924140930176\n",
      "Epoch 5, Batch 14, Generator Loss: 0.7238492965698242, Discriminator Loss: 1.3782598972320557\n",
      "Epoch 5, Batch 15, Generator Loss: 0.7330636978149414, Discriminator Loss: 1.3740489482879639\n",
      "Epoch 5, Batch 16, Generator Loss: 0.7427912354469299, Discriminator Loss: 1.3626545667648315\n",
      "Epoch 5, Batch 17, Generator Loss: 0.7284966707229614, Discriminator Loss: 1.3758749961853027\n",
      "Epoch 5, Batch 18, Generator Loss: 0.7315536737442017, Discriminator Loss: 1.3194024562835693\n",
      "Epoch 5, Batch 19, Generator Loss: 0.7253351211547852, Discriminator Loss: 1.4029819965362549\n",
      "Epoch 5, Batch 20, Generator Loss: 0.7452927827835083, Discriminator Loss: 1.3171440362930298\n",
      "Epoch 5, Batch 21, Generator Loss: 0.7332608699798584, Discriminator Loss: 1.359540343284607\n",
      "Epoch 5, Batch 22, Generator Loss: 0.7430463433265686, Discriminator Loss: 1.3693472146987915\n",
      "Epoch 5, Batch 23, Generator Loss: 0.7346048355102539, Discriminator Loss: 1.3805503845214844\n",
      "Epoch 5, Batch 24, Generator Loss: 0.7314242124557495, Discriminator Loss: 1.3660314083099365\n",
      "Epoch 5, Batch 25, Generator Loss: 0.7281779050827026, Discriminator Loss: 1.368609070777893\n",
      "Epoch 5, Batch 26, Generator Loss: 0.7251876592636108, Discriminator Loss: 1.4116334915161133\n",
      "Epoch 5, Batch 27, Generator Loss: 0.7443645000457764, Discriminator Loss: 1.375744104385376\n",
      "Epoch 5, Batch 28, Generator Loss: 0.7277871966362, Discriminator Loss: 1.3607268333435059\n",
      "Epoch 5, Batch 29, Generator Loss: 0.7305253744125366, Discriminator Loss: 1.3497570753097534\n",
      "Epoch 5, Batch 30, Generator Loss: 0.7234528660774231, Discriminator Loss: 1.4123361110687256\n",
      "Epoch 5, Batch 31, Generator Loss: 0.7234607934951782, Discriminator Loss: 1.3744332790374756\n",
      "Epoch 5, Batch 32, Generator Loss: 0.7332911491394043, Discriminator Loss: 1.3839353322982788\n",
      "Epoch 5, Batch 33, Generator Loss: 0.727699339389801, Discriminator Loss: 1.3695111274719238\n",
      "Epoch 5, Batch 34, Generator Loss: 0.7379341721534729, Discriminator Loss: 1.3879218101501465\n",
      "Epoch 5, Batch 35, Generator Loss: 0.7252271175384521, Discriminator Loss: 1.3428064584732056\n",
      "Epoch 5, Batch 36, Generator Loss: 0.7291702032089233, Discriminator Loss: 1.3462083339691162\n",
      "Epoch 5, Batch 37, Generator Loss: 0.733963131904602, Discriminator Loss: 1.38288152217865\n",
      "Epoch 5, Batch 38, Generator Loss: 0.7401432394981384, Discriminator Loss: 1.331046223640442\n",
      "Epoch 5, Batch 39, Generator Loss: 0.7165707945823669, Discriminator Loss: 1.4017078876495361\n",
      "Epoch 5, Batch 40, Generator Loss: 0.7236920595169067, Discriminator Loss: 1.3897736072540283\n",
      "Epoch 5, Batch 41, Generator Loss: 0.7310208082199097, Discriminator Loss: 1.379578948020935\n",
      "Epoch 5, Batch 42, Generator Loss: 0.7278561592102051, Discriminator Loss: 1.3886051177978516\n",
      "Epoch 5, Batch 43, Generator Loss: 0.7213312387466431, Discriminator Loss: 1.404470443725586\n",
      "Epoch 5, Batch 44, Generator Loss: 0.7245436906814575, Discriminator Loss: 1.349203109741211\n",
      "Epoch 5, Batch 45, Generator Loss: 0.7324438095092773, Discriminator Loss: 1.318467378616333\n",
      "Epoch 5, Batch 46, Generator Loss: 0.7262552976608276, Discriminator Loss: 1.3246766328811646\n",
      "Epoch 5, Batch 47, Generator Loss: 0.7267735004425049, Discriminator Loss: 1.3436415195465088\n",
      "Epoch 5, Batch 48, Generator Loss: 0.7228511571884155, Discriminator Loss: 1.3633460998535156\n",
      "Epoch 5, Batch 49, Generator Loss: 0.7285019755363464, Discriminator Loss: 1.3447492122650146\n",
      "Epoch 5, Batch 50, Generator Loss: 0.7435031533241272, Discriminator Loss: 1.2877147197723389\n",
      "Epoch 5, Batch 51, Generator Loss: 0.7276014685630798, Discriminator Loss: 1.3968358039855957\n",
      "Epoch 5, Batch 52, Generator Loss: 0.7229301929473877, Discriminator Loss: 1.3171502351760864\n",
      "Epoch 5, Batch 53, Generator Loss: 0.7330065965652466, Discriminator Loss: 1.3376141786575317\n",
      "Epoch 5, Batch 54, Generator Loss: 0.7302820682525635, Discriminator Loss: 1.3696885108947754\n",
      "Epoch 5, Batch 55, Generator Loss: 0.7303356528282166, Discriminator Loss: 1.311650276184082\n",
      "Epoch 5, Batch 56, Generator Loss: 0.7195797562599182, Discriminator Loss: 1.4019887447357178\n",
      "Epoch 5, Batch 57, Generator Loss: 0.7202832102775574, Discriminator Loss: 1.3606727123260498\n",
      "Epoch 5, Batch 58, Generator Loss: 0.7241683006286621, Discriminator Loss: 1.3260704278945923\n",
      "Epoch 5, Batch 59, Generator Loss: 0.7200400829315186, Discriminator Loss: 1.3285772800445557\n",
      "Epoch 5, Batch 60, Generator Loss: 0.7355242967605591, Discriminator Loss: 1.3674039840698242\n",
      "Epoch 5, Batch 61, Generator Loss: 0.7282130122184753, Discriminator Loss: 1.2998707294464111\n",
      "Epoch 5, Batch 62, Generator Loss: 0.7366308569908142, Discriminator Loss: 1.341765284538269\n",
      "Epoch 5, Batch 63, Generator Loss: 0.7419514656066895, Discriminator Loss: 1.3334875106811523\n",
      "Epoch 5, Batch 64, Generator Loss: 0.7271620035171509, Discriminator Loss: 1.3731434345245361\n",
      "Epoch 5, Batch 65, Generator Loss: 0.730398952960968, Discriminator Loss: 1.319285273551941\n",
      "Epoch 5, Batch 66, Generator Loss: 0.7294877767562866, Discriminator Loss: 1.3887792825698853\n",
      "Epoch 5, Batch 67, Generator Loss: 0.7187995910644531, Discriminator Loss: 1.3805387020111084\n",
      "Epoch 5, Batch 68, Generator Loss: 0.7282469272613525, Discriminator Loss: 1.3818752765655518\n",
      "Epoch 5, Batch 69, Generator Loss: 0.7257672548294067, Discriminator Loss: 1.3391242027282715\n",
      "Epoch 5, Batch 70, Generator Loss: 0.7278872728347778, Discriminator Loss: 1.3130111694335938\n",
      "Epoch 5, Batch 71, Generator Loss: 0.7329099774360657, Discriminator Loss: 1.3364243507385254\n",
      "Epoch 5, Batch 72, Generator Loss: 0.7190151214599609, Discriminator Loss: 1.4210102558135986\n",
      "Epoch 5, Batch 73, Generator Loss: 0.7248296737670898, Discriminator Loss: 1.4060566425323486\n",
      "Epoch 5, Batch 74, Generator Loss: 0.7325068712234497, Discriminator Loss: 1.4034088850021362\n",
      "Epoch 5, Batch 75, Generator Loss: 0.7209445238113403, Discriminator Loss: 1.3528183698654175\n",
      "Epoch 5, Batch 76, Generator Loss: 0.7265666723251343, Discriminator Loss: 1.4016344547271729\n",
      "Epoch 5, Batch 77, Generator Loss: 0.7439248561859131, Discriminator Loss: 1.4085232019424438\n",
      "Epoch 5, Batch 78, Generator Loss: 0.7375391721725464, Discriminator Loss: 1.3742672204971313\n",
      "Epoch 5, Batch 79, Generator Loss: 0.7315683364868164, Discriminator Loss: 1.3918815851211548\n",
      "Epoch 5, Batch 80, Generator Loss: 0.7402635812759399, Discriminator Loss: 1.3721961975097656\n",
      "Epoch 5, Batch 81, Generator Loss: 0.738200306892395, Discriminator Loss: 1.367427110671997\n",
      "Epoch 5, Batch 82, Generator Loss: 0.7358518838882446, Discriminator Loss: 1.323249101638794\n",
      "Epoch 5, Batch 83, Generator Loss: 0.7311577200889587, Discriminator Loss: 1.363694190979004\n",
      "Epoch 5, Batch 84, Generator Loss: 0.7364950776100159, Discriminator Loss: 1.3956358432769775\n",
      "Epoch 5, Batch 85, Generator Loss: 0.7318451404571533, Discriminator Loss: 1.330240249633789\n",
      "Epoch 5, Batch 86, Generator Loss: 0.7206429243087769, Discriminator Loss: 1.4061839580535889\n",
      "Epoch 5, Batch 87, Generator Loss: 0.7277839183807373, Discriminator Loss: 1.3167312145233154\n",
      "Epoch 5, Batch 88, Generator Loss: 0.7287379503250122, Discriminator Loss: 1.327755093574524\n",
      "Epoch 5, Batch 89, Generator Loss: 0.7324970364570618, Discriminator Loss: 1.3744330406188965\n",
      "Epoch 5, Batch 90, Generator Loss: 0.729413628578186, Discriminator Loss: 1.3583917617797852\n",
      "Epoch 5, Batch 91, Generator Loss: 0.7270033359527588, Discriminator Loss: 1.398654818534851\n",
      "Epoch 6, Batch 1, Generator Loss: 0.7243198752403259, Discriminator Loss: 1.3591105937957764\n",
      "Epoch 6, Batch 2, Generator Loss: 0.7311801910400391, Discriminator Loss: 1.3655284643173218\n",
      "Epoch 6, Batch 3, Generator Loss: 0.7344120144844055, Discriminator Loss: 1.3228734731674194\n",
      "Epoch 6, Batch 4, Generator Loss: 0.7245292663574219, Discriminator Loss: 1.3693745136260986\n",
      "Epoch 6, Batch 5, Generator Loss: 0.7408320903778076, Discriminator Loss: 1.3486391305923462\n",
      "Epoch 6, Batch 6, Generator Loss: 0.7323004007339478, Discriminator Loss: 1.3649451732635498\n",
      "Epoch 6, Batch 7, Generator Loss: 0.7243670225143433, Discriminator Loss: 1.357757568359375\n",
      "Epoch 6, Batch 8, Generator Loss: 0.7319324016571045, Discriminator Loss: 1.3528738021850586\n",
      "Epoch 6, Batch 9, Generator Loss: 0.729182779788971, Discriminator Loss: 1.363670825958252\n",
      "Epoch 6, Batch 10, Generator Loss: 0.7438023090362549, Discriminator Loss: 1.3185865879058838\n",
      "Epoch 6, Batch 11, Generator Loss: 0.7222269177436829, Discriminator Loss: 1.3643019199371338\n",
      "Epoch 6, Batch 12, Generator Loss: 0.7297317981719971, Discriminator Loss: 1.383191704750061\n",
      "Epoch 6, Batch 13, Generator Loss: 0.7266582250595093, Discriminator Loss: 1.3440206050872803\n",
      "Epoch 6, Batch 14, Generator Loss: 0.7326239347457886, Discriminator Loss: 1.354480504989624\n",
      "Epoch 6, Batch 15, Generator Loss: 0.732205331325531, Discriminator Loss: 1.3566973209381104\n",
      "Epoch 6, Batch 16, Generator Loss: 0.731092095375061, Discriminator Loss: 1.3519251346588135\n",
      "Epoch 6, Batch 17, Generator Loss: 0.7241935133934021, Discriminator Loss: 1.3674708604812622\n",
      "Epoch 6, Batch 18, Generator Loss: 0.7329744100570679, Discriminator Loss: 1.3008460998535156\n",
      "Epoch 6, Batch 19, Generator Loss: 0.7395387887954712, Discriminator Loss: 1.3735682964324951\n",
      "Epoch 6, Batch 20, Generator Loss: 0.7308984398841858, Discriminator Loss: 1.3129335641860962\n",
      "Epoch 6, Batch 21, Generator Loss: 0.7192507386207581, Discriminator Loss: 1.3575284481048584\n",
      "Epoch 6, Batch 22, Generator Loss: 0.728704571723938, Discriminator Loss: 1.3761130571365356\n",
      "Epoch 6, Batch 23, Generator Loss: 0.7425470352172852, Discriminator Loss: 1.3671092987060547\n",
      "Epoch 6, Batch 24, Generator Loss: 0.7184407711029053, Discriminator Loss: 1.3623895645141602\n",
      "Epoch 6, Batch 25, Generator Loss: 0.7264066934585571, Discriminator Loss: 1.3591060638427734\n",
      "Epoch 6, Batch 26, Generator Loss: 0.7162197828292847, Discriminator Loss: 1.4047513008117676\n",
      "Epoch 6, Batch 27, Generator Loss: 0.7233203649520874, Discriminator Loss: 1.380286455154419\n",
      "Epoch 6, Batch 28, Generator Loss: 0.7241500616073608, Discriminator Loss: 1.3483695983886719\n",
      "Epoch 6, Batch 29, Generator Loss: 0.7116996049880981, Discriminator Loss: 1.3485581874847412\n",
      "Epoch 6, Batch 30, Generator Loss: 0.7271285057067871, Discriminator Loss: 1.387913703918457\n",
      "Epoch 6, Batch 31, Generator Loss: 0.728661060333252, Discriminator Loss: 1.3547381162643433\n",
      "Epoch 6, Batch 32, Generator Loss: 0.7234666347503662, Discriminator Loss: 1.3771252632141113\n",
      "Epoch 6, Batch 33, Generator Loss: 0.7278127670288086, Discriminator Loss: 1.3594980239868164\n",
      "Epoch 6, Batch 34, Generator Loss: 0.7313443422317505, Discriminator Loss: 1.3865482807159424\n",
      "Epoch 6, Batch 35, Generator Loss: 0.7209799289703369, Discriminator Loss: 1.335994839668274\n",
      "Epoch 6, Batch 36, Generator Loss: 0.7160599231719971, Discriminator Loss: 1.3379123210906982\n",
      "Epoch 6, Batch 37, Generator Loss: 0.7158616781234741, Discriminator Loss: 1.3784141540527344\n",
      "Epoch 6, Batch 38, Generator Loss: 0.7209212779998779, Discriminator Loss: 1.3324135541915894\n",
      "Epoch 6, Batch 39, Generator Loss: 0.7261102199554443, Discriminator Loss: 1.385104775428772\n",
      "Epoch 6, Batch 40, Generator Loss: 0.7216897010803223, Discriminator Loss: 1.3861255645751953\n",
      "Epoch 6, Batch 41, Generator Loss: 0.7192399501800537, Discriminator Loss: 1.3912214040756226\n",
      "Epoch 6, Batch 42, Generator Loss: 0.7327027916908264, Discriminator Loss: 1.3714845180511475\n",
      "Epoch 6, Batch 43, Generator Loss: 0.7265416383743286, Discriminator Loss: 1.3962996006011963\n",
      "Epoch 6, Batch 44, Generator Loss: 0.7307156324386597, Discriminator Loss: 1.3342301845550537\n",
      "Epoch 6, Batch 45, Generator Loss: 0.7317276000976562, Discriminator Loss: 1.3018054962158203\n",
      "Epoch 6, Batch 46, Generator Loss: 0.7283433079719543, Discriminator Loss: 1.3119251728057861\n",
      "Epoch 6, Batch 47, Generator Loss: 0.7239787578582764, Discriminator Loss: 1.3329485654830933\n",
      "Epoch 6, Batch 48, Generator Loss: 0.7217200398445129, Discriminator Loss: 1.360725998878479\n",
      "Epoch 6, Batch 49, Generator Loss: 0.7325495481491089, Discriminator Loss: 1.3317489624023438\n",
      "Epoch 6, Batch 50, Generator Loss: 0.7245444655418396, Discriminator Loss: 1.2824980020523071\n",
      "Epoch 6, Batch 51, Generator Loss: 0.7301079630851746, Discriminator Loss: 1.3932068347930908\n",
      "Epoch 6, Batch 52, Generator Loss: 0.7320470809936523, Discriminator Loss: 1.2925362586975098\n",
      "Epoch 6, Batch 53, Generator Loss: 0.7234866619110107, Discriminator Loss: 1.3376617431640625\n",
      "Epoch 6, Batch 54, Generator Loss: 0.7337030172348022, Discriminator Loss: 1.3527119159698486\n",
      "Epoch 6, Batch 55, Generator Loss: 0.719879686832428, Discriminator Loss: 1.3040494918823242\n",
      "Epoch 6, Batch 56, Generator Loss: 0.7238532304763794, Discriminator Loss: 1.3961716890335083\n",
      "Epoch 6, Batch 57, Generator Loss: 0.7189067602157593, Discriminator Loss: 1.3374027013778687\n",
      "Epoch 6, Batch 58, Generator Loss: 0.7352262735366821, Discriminator Loss: 1.3030791282653809\n",
      "Epoch 6, Batch 59, Generator Loss: 0.7232828140258789, Discriminator Loss: 1.3146226406097412\n",
      "Epoch 6, Batch 60, Generator Loss: 0.7190965414047241, Discriminator Loss: 1.3697307109832764\n",
      "Epoch 6, Batch 61, Generator Loss: 0.721434473991394, Discriminator Loss: 1.2968299388885498\n",
      "Epoch 6, Batch 62, Generator Loss: 0.7176505327224731, Discriminator Loss: 1.3428292274475098\n",
      "Epoch 6, Batch 63, Generator Loss: 0.7259411215782166, Discriminator Loss: 1.3249762058258057\n",
      "Epoch 6, Batch 64, Generator Loss: 0.7280836701393127, Discriminator Loss: 1.364274263381958\n",
      "Epoch 6, Batch 65, Generator Loss: 0.7350426912307739, Discriminator Loss: 1.303645133972168\n",
      "Epoch 6, Batch 66, Generator Loss: 0.7329975962638855, Discriminator Loss: 1.3784091472625732\n",
      "Epoch 6, Batch 67, Generator Loss: 0.7370567321777344, Discriminator Loss: 1.355055570602417\n",
      "Epoch 6, Batch 68, Generator Loss: 0.7328925728797913, Discriminator Loss: 1.3748018741607666\n",
      "Epoch 6, Batch 69, Generator Loss: 0.7268806099891663, Discriminator Loss: 1.3267755508422852\n",
      "Epoch 6, Batch 70, Generator Loss: 0.7218471169471741, Discriminator Loss: 1.2976332902908325\n",
      "Epoch 6, Batch 71, Generator Loss: 0.7306815385818481, Discriminator Loss: 1.3296911716461182\n",
      "Epoch 6, Batch 72, Generator Loss: 0.7270480394363403, Discriminator Loss: 1.40363347530365\n",
      "Epoch 6, Batch 73, Generator Loss: 0.7240356206893921, Discriminator Loss: 1.3966484069824219\n",
      "Epoch 6, Batch 74, Generator Loss: 0.7358488440513611, Discriminator Loss: 1.3936983346939087\n",
      "Epoch 6, Batch 75, Generator Loss: 0.7266408205032349, Discriminator Loss: 1.3353520631790161\n",
      "Epoch 6, Batch 76, Generator Loss: 0.7333502769470215, Discriminator Loss: 1.3868329524993896\n",
      "Epoch 6, Batch 77, Generator Loss: 0.7236632108688354, Discriminator Loss: 1.4125940799713135\n",
      "Epoch 6, Batch 78, Generator Loss: 0.7425366640090942, Discriminator Loss: 1.365238904953003\n",
      "Epoch 6, Batch 79, Generator Loss: 0.7365227937698364, Discriminator Loss: 1.3814388513565063\n",
      "Epoch 6, Batch 80, Generator Loss: 0.7364964485168457, Discriminator Loss: 1.377586841583252\n",
      "Epoch 6, Batch 81, Generator Loss: 0.7257338762283325, Discriminator Loss: 1.3698320388793945\n",
      "Epoch 6, Batch 82, Generator Loss: 0.7434535026550293, Discriminator Loss: 1.302040696144104\n",
      "Epoch 6, Batch 83, Generator Loss: 0.7300150394439697, Discriminator Loss: 1.3550515174865723\n",
      "Epoch 6, Batch 84, Generator Loss: 0.7207441926002502, Discriminator Loss: 1.4110667705535889\n",
      "Epoch 6, Batch 85, Generator Loss: 0.7109794020652771, Discriminator Loss: 1.3339577913284302\n",
      "Epoch 6, Batch 86, Generator Loss: 0.7343227863311768, Discriminator Loss: 1.3908412456512451\n",
      "Epoch 6, Batch 87, Generator Loss: 0.7240929007530212, Discriminator Loss: 1.3086804151535034\n",
      "Epoch 6, Batch 88, Generator Loss: 0.7314627766609192, Discriminator Loss: 1.3103364706039429\n",
      "Epoch 6, Batch 89, Generator Loss: 0.7338443994522095, Discriminator Loss: 1.3670119047164917\n",
      "Epoch 6, Batch 90, Generator Loss: 0.7167335748672485, Discriminator Loss: 1.3584065437316895\n",
      "Epoch 6, Batch 91, Generator Loss: 0.7372034788131714, Discriminator Loss: 1.389306664466858\n",
      "Epoch 7, Batch 1, Generator Loss: 0.7280689477920532, Discriminator Loss: 1.3354681730270386\n",
      "Epoch 7, Batch 2, Generator Loss: 0.7279958724975586, Discriminator Loss: 1.3614839315414429\n",
      "Epoch 7, Batch 3, Generator Loss: 0.7283945083618164, Discriminator Loss: 1.3035944700241089\n",
      "Epoch 7, Batch 4, Generator Loss: 0.7328850030899048, Discriminator Loss: 1.3489993810653687\n",
      "Epoch 7, Batch 5, Generator Loss: 0.734573483467102, Discriminator Loss: 1.3465485572814941\n",
      "Epoch 7, Batch 6, Generator Loss: 0.7234306335449219, Discriminator Loss: 1.369821310043335\n",
      "Epoch 7, Batch 7, Generator Loss: 0.7267032861709595, Discriminator Loss: 1.3450257778167725\n",
      "Epoch 7, Batch 8, Generator Loss: 0.7395491600036621, Discriminator Loss: 1.329169511795044\n",
      "Epoch 7, Batch 9, Generator Loss: 0.7118062973022461, Discriminator Loss: 1.370784044265747\n",
      "Epoch 7, Batch 10, Generator Loss: 0.7260856628417969, Discriminator Loss: 1.3279958963394165\n",
      "Epoch 7, Batch 11, Generator Loss: 0.733623743057251, Discriminator Loss: 1.3432714939117432\n",
      "Epoch 7, Batch 12, Generator Loss: 0.7354791164398193, Discriminator Loss: 1.3756608963012695\n",
      "Epoch 7, Batch 13, Generator Loss: 0.7352729439735413, Discriminator Loss: 1.3357847929000854\n",
      "Epoch 7, Batch 14, Generator Loss: 0.7384676933288574, Discriminator Loss: 1.3395198583602905\n",
      "Epoch 7, Batch 15, Generator Loss: 0.7285248041152954, Discriminator Loss: 1.3557395935058594\n",
      "Epoch 7, Batch 16, Generator Loss: 0.7271530032157898, Discriminator Loss: 1.3433860540390015\n",
      "Epoch 7, Batch 17, Generator Loss: 0.7398495674133301, Discriminator Loss: 1.3505585193634033\n",
      "Epoch 7, Batch 18, Generator Loss: 0.7356702089309692, Discriminator Loss: 1.2897899150848389\n",
      "Epoch 7, Batch 19, Generator Loss: 0.7306331396102905, Discriminator Loss: 1.3733350038528442\n",
      "Epoch 7, Batch 20, Generator Loss: 0.7273743748664856, Discriminator Loss: 1.3057806491851807\n",
      "Epoch 7, Batch 21, Generator Loss: 0.7356249094009399, Discriminator Loss: 1.3370394706726074\n",
      "Epoch 7, Batch 22, Generator Loss: 0.7316340208053589, Discriminator Loss: 1.3675720691680908\n",
      "Epoch 7, Batch 23, Generator Loss: 0.7299184799194336, Discriminator Loss: 1.367802619934082\n",
      "Epoch 7, Batch 24, Generator Loss: 0.7391745448112488, Discriminator Loss: 1.33800208568573\n",
      "Epoch 7, Batch 25, Generator Loss: 0.7264285683631897, Discriminator Loss: 1.3509211540222168\n",
      "Epoch 7, Batch 26, Generator Loss: 0.7287876605987549, Discriminator Loss: 1.396111011505127\n",
      "Epoch 7, Batch 27, Generator Loss: 0.7378208637237549, Discriminator Loss: 1.3711681365966797\n",
      "Epoch 7, Batch 28, Generator Loss: 0.7213597297668457, Discriminator Loss: 1.3412702083587646\n",
      "Epoch 7, Batch 29, Generator Loss: 0.7239859700202942, Discriminator Loss: 1.3340903520584106\n",
      "Epoch 7, Batch 30, Generator Loss: 0.7399039268493652, Discriminator Loss: 1.3736188411712646\n",
      "Epoch 7, Batch 31, Generator Loss: 0.7400978803634644, Discriminator Loss: 1.3350815773010254\n",
      "Epoch 7, Batch 32, Generator Loss: 0.7397448420524597, Discriminator Loss: 1.3594634532928467\n",
      "Epoch 7, Batch 33, Generator Loss: 0.7343717813491821, Discriminator Loss: 1.3468281030654907\n",
      "Epoch 7, Batch 34, Generator Loss: 0.7249841690063477, Discriminator Loss: 1.378042459487915\n",
      "Epoch 7, Batch 35, Generator Loss: 0.7287484407424927, Discriminator Loss: 1.326429843902588\n",
      "Epoch 7, Batch 36, Generator Loss: 0.7286493182182312, Discriminator Loss: 1.317840576171875\n",
      "Epoch 7, Batch 37, Generator Loss: 0.7380180358886719, Discriminator Loss: 1.3582277297973633\n",
      "Epoch 7, Batch 38, Generator Loss: 0.7240935564041138, Discriminator Loss: 1.3219481706619263\n",
      "Epoch 7, Batch 39, Generator Loss: 0.735543429851532, Discriminator Loss: 1.3728705644607544\n",
      "Epoch 7, Batch 40, Generator Loss: 0.7328559160232544, Discriminator Loss: 1.3748887777328491\n",
      "Epoch 7, Batch 41, Generator Loss: 0.7349541783332825, Discriminator Loss: 1.367714285850525\n",
      "Epoch 7, Batch 42, Generator Loss: 0.7296297550201416, Discriminator Loss: 1.3607699871063232\n",
      "Epoch 7, Batch 43, Generator Loss: 0.7150098085403442, Discriminator Loss: 1.396703839302063\n",
      "Epoch 7, Batch 44, Generator Loss: 0.723724365234375, Discriminator Loss: 1.3339693546295166\n",
      "Epoch 7, Batch 45, Generator Loss: 0.7319667339324951, Discriminator Loss: 1.294389009475708\n",
      "Epoch 7, Batch 46, Generator Loss: 0.7217790484428406, Discriminator Loss: 1.3048615455627441\n",
      "Epoch 7, Batch 47, Generator Loss: 0.7157716751098633, Discriminator Loss: 1.3367950916290283\n",
      "Epoch 7, Batch 48, Generator Loss: 0.7262896299362183, Discriminator Loss: 1.3419091701507568\n",
      "Epoch 7, Batch 49, Generator Loss: 0.7373943328857422, Discriminator Loss: 1.3195219039916992\n",
      "Epoch 7, Batch 50, Generator Loss: 0.7222837209701538, Discriminator Loss: 1.2776087522506714\n",
      "Epoch 7, Batch 51, Generator Loss: 0.7212671041488647, Discriminator Loss: 1.3856091499328613\n",
      "Epoch 7, Batch 52, Generator Loss: 0.7320780754089355, Discriminator Loss: 1.2841780185699463\n",
      "Epoch 7, Batch 53, Generator Loss: 0.7266530990600586, Discriminator Loss: 1.3218750953674316\n",
      "Epoch 7, Batch 54, Generator Loss: 0.7272963523864746, Discriminator Loss: 1.3611422777175903\n",
      "Epoch 7, Batch 55, Generator Loss: 0.7354587316513062, Discriminator Loss: 1.2830922603607178\n",
      "Epoch 7, Batch 56, Generator Loss: 0.7407451868057251, Discriminator Loss: 1.379743218421936\n",
      "Epoch 7, Batch 57, Generator Loss: 0.7320914268493652, Discriminator Loss: 1.3276503086090088\n",
      "Epoch 7, Batch 58, Generator Loss: 0.7282215356826782, Discriminator Loss: 1.2969671487808228\n",
      "Epoch 7, Batch 59, Generator Loss: 0.7269536256790161, Discriminator Loss: 1.3086107969284058\n",
      "Epoch 7, Batch 60, Generator Loss: 0.7277354001998901, Discriminator Loss: 1.3564553260803223\n",
      "Epoch 7, Batch 61, Generator Loss: 0.7377102971076965, Discriminator Loss: 1.2742369174957275\n",
      "Epoch 7, Batch 62, Generator Loss: 0.7249606847763062, Discriminator Loss: 1.3294477462768555\n",
      "Epoch 7, Batch 63, Generator Loss: 0.7320513725280762, Discriminator Loss: 1.3150050640106201\n",
      "Epoch 7, Batch 64, Generator Loss: 0.7388352155685425, Discriminator Loss: 1.352889060974121\n",
      "Epoch 7, Batch 65, Generator Loss: 0.7332264184951782, Discriminator Loss: 1.2937594652175903\n",
      "Epoch 7, Batch 66, Generator Loss: 0.726661205291748, Discriminator Loss: 1.3735015392303467\n",
      "Epoch 7, Batch 67, Generator Loss: 0.7455620169639587, Discriminator Loss: 1.350630760192871\n",
      "Epoch 7, Batch 68, Generator Loss: 0.7335825562477112, Discriminator Loss: 1.3693488836288452\n",
      "Epoch 7, Batch 69, Generator Loss: 0.7383437156677246, Discriminator Loss: 1.30385422706604\n",
      "Epoch 7, Batch 70, Generator Loss: 0.721707820892334, Discriminator Loss: 1.2927889823913574\n",
      "Epoch 7, Batch 71, Generator Loss: 0.7300336360931396, Discriminator Loss: 1.319639801979065\n",
      "Epoch 7, Batch 72, Generator Loss: 0.7332504987716675, Discriminator Loss: 1.389655590057373\n",
      "Epoch 7, Batch 73, Generator Loss: 0.738012969493866, Discriminator Loss: 1.3826066255569458\n",
      "Epoch 7, Batch 74, Generator Loss: 0.7403230667114258, Discriminator Loss: 1.3930774927139282\n",
      "Epoch 7, Batch 75, Generator Loss: 0.7221640348434448, Discriminator Loss: 1.3329596519470215\n",
      "Epoch 7, Batch 76, Generator Loss: 0.7270223498344421, Discriminator Loss: 1.3920807838439941\n",
      "Epoch 7, Batch 77, Generator Loss: 0.7326865792274475, Discriminator Loss: 1.4059343338012695\n",
      "Epoch 7, Batch 78, Generator Loss: 0.7314307689666748, Discriminator Loss: 1.367034673690796\n",
      "Epoch 7, Batch 79, Generator Loss: 0.7420860528945923, Discriminator Loss: 1.3778212070465088\n",
      "Epoch 7, Batch 80, Generator Loss: 0.746171772480011, Discriminator Loss: 1.355307698249817\n",
      "Epoch 7, Batch 81, Generator Loss: 0.7504419684410095, Discriminator Loss: 1.3491778373718262\n",
      "Epoch 7, Batch 82, Generator Loss: 0.7406080961227417, Discriminator Loss: 1.2969162464141846\n",
      "Epoch 7, Batch 83, Generator Loss: 0.7339344024658203, Discriminator Loss: 1.3505609035491943\n",
      "Epoch 7, Batch 84, Generator Loss: 0.7274593114852905, Discriminator Loss: 1.3961247205734253\n",
      "Epoch 7, Batch 85, Generator Loss: 0.7187944650650024, Discriminator Loss: 1.312354564666748\n",
      "Epoch 7, Batch 86, Generator Loss: 0.7355056405067444, Discriminator Loss: 1.3966376781463623\n",
      "Epoch 7, Batch 87, Generator Loss: 0.7289905548095703, Discriminator Loss: 1.3012239933013916\n",
      "Epoch 7, Batch 88, Generator Loss: 0.7258523106575012, Discriminator Loss: 1.307971477508545\n",
      "Epoch 7, Batch 89, Generator Loss: 0.7309630513191223, Discriminator Loss: 1.3553431034088135\n",
      "Epoch 7, Batch 90, Generator Loss: 0.738216757774353, Discriminator Loss: 1.324103832244873\n",
      "Epoch 7, Batch 91, Generator Loss: 0.72657310962677, Discriminator Loss: 1.3965129852294922\n",
      "Epoch 8, Batch 1, Generator Loss: 0.7206002473831177, Discriminator Loss: 1.3367165327072144\n",
      "Epoch 8, Batch 2, Generator Loss: 0.7383074164390564, Discriminator Loss: 1.3461573123931885\n",
      "Epoch 8, Batch 3, Generator Loss: 0.7265186309814453, Discriminator Loss: 1.2964818477630615\n",
      "Epoch 8, Batch 4, Generator Loss: 0.7419912815093994, Discriminator Loss: 1.3320189714431763\n",
      "Epoch 8, Batch 5, Generator Loss: 0.7334388494491577, Discriminator Loss: 1.3466066122055054\n",
      "Epoch 8, Batch 6, Generator Loss: 0.7307329177856445, Discriminator Loss: 1.355003833770752\n",
      "Epoch 8, Batch 7, Generator Loss: 0.7357292175292969, Discriminator Loss: 1.3360376358032227\n",
      "Epoch 8, Batch 8, Generator Loss: 0.728272557258606, Discriminator Loss: 1.335024118423462\n",
      "Epoch 8, Batch 9, Generator Loss: 0.7206994891166687, Discriminator Loss: 1.359168291091919\n",
      "Epoch 8, Batch 10, Generator Loss: 0.7455941438674927, Discriminator Loss: 1.3045053482055664\n",
      "Epoch 8, Batch 11, Generator Loss: 0.7418930530548096, Discriminator Loss: 1.3385882377624512\n",
      "Epoch 8, Batch 12, Generator Loss: 0.7211867570877075, Discriminator Loss: 1.373463749885559\n",
      "Epoch 8, Batch 13, Generator Loss: 0.7336894869804382, Discriminator Loss: 1.3265914916992188\n",
      "Epoch 8, Batch 14, Generator Loss: 0.7155896425247192, Discriminator Loss: 1.3525071144104004\n",
      "Epoch 8, Batch 15, Generator Loss: 0.7321746349334717, Discriminator Loss: 1.3500752449035645\n",
      "Epoch 8, Batch 16, Generator Loss: 0.7258358001708984, Discriminator Loss: 1.341935396194458\n",
      "Epoch 8, Batch 17, Generator Loss: 0.7320300936698914, Discriminator Loss: 1.3509275913238525\n",
      "Epoch 8, Batch 18, Generator Loss: 0.7318531274795532, Discriminator Loss: 1.2763725519180298\n",
      "Epoch 8, Batch 19, Generator Loss: 0.7242457866668701, Discriminator Loss: 1.3722891807556152\n",
      "Epoch 8, Batch 20, Generator Loss: 0.7251121401786804, Discriminator Loss: 1.295807123184204\n",
      "Epoch 8, Batch 21, Generator Loss: 0.7402337789535522, Discriminator Loss: 1.3252332210540771\n",
      "Epoch 8, Batch 22, Generator Loss: 0.730636715888977, Discriminator Loss: 1.3667845726013184\n",
      "Epoch 8, Batch 23, Generator Loss: 0.7234606742858887, Discriminator Loss: 1.3744291067123413\n",
      "Epoch 8, Batch 24, Generator Loss: 0.7296947240829468, Discriminator Loss: 1.3418874740600586\n",
      "Epoch 8, Batch 25, Generator Loss: 0.7322579622268677, Discriminator Loss: 1.3374801874160767\n",
      "Epoch 8, Batch 26, Generator Loss: 0.7317119240760803, Discriminator Loss: 1.3842545747756958\n",
      "Epoch 8, Batch 27, Generator Loss: 0.7315402626991272, Discriminator Loss: 1.365522861480713\n",
      "Epoch 8, Batch 28, Generator Loss: 0.7333536744117737, Discriminator Loss: 1.3297982215881348\n",
      "Epoch 8, Batch 29, Generator Loss: 0.7382210493087769, Discriminator Loss: 1.3091890811920166\n",
      "Epoch 8, Batch 30, Generator Loss: 0.7389292120933533, Discriminator Loss: 1.3776612281799316\n",
      "Epoch 8, Batch 31, Generator Loss: 0.7356014251708984, Discriminator Loss: 1.3361555337905884\n",
      "Epoch 8, Batch 32, Generator Loss: 0.7264952659606934, Discriminator Loss: 1.37372624874115\n",
      "Epoch 8, Batch 33, Generator Loss: 0.7454091310501099, Discriminator Loss: 1.3342859745025635\n",
      "Epoch 8, Batch 34, Generator Loss: 0.7369004487991333, Discriminator Loss: 1.3711531162261963\n",
      "Epoch 8, Batch 35, Generator Loss: 0.7233339548110962, Discriminator Loss: 1.3253958225250244\n",
      "Epoch 8, Batch 36, Generator Loss: 0.7190073728561401, Discriminator Loss: 1.3202893733978271\n",
      "Epoch 8, Batch 37, Generator Loss: 0.7263686656951904, Discriminator Loss: 1.3588447570800781\n",
      "Epoch 8, Batch 38, Generator Loss: 0.726390540599823, Discriminator Loss: 1.3122584819793701\n",
      "Epoch 8, Batch 39, Generator Loss: 0.7406834363937378, Discriminator Loss: 1.3671976327896118\n",
      "Epoch 8, Batch 40, Generator Loss: 0.7359764575958252, Discriminator Loss: 1.3624608516693115\n",
      "Epoch 8, Batch 41, Generator Loss: 0.7402660846710205, Discriminator Loss: 1.3592956066131592\n",
      "Epoch 8, Batch 42, Generator Loss: 0.7408454418182373, Discriminator Loss: 1.3486557006835938\n",
      "Epoch 8, Batch 43, Generator Loss: 0.7242828011512756, Discriminator Loss: 1.3906762599945068\n",
      "Epoch 8, Batch 44, Generator Loss: 0.7211377620697021, Discriminator Loss: 1.3264975547790527\n",
      "Epoch 8, Batch 45, Generator Loss: 0.7280824184417725, Discriminator Loss: 1.292062759399414\n",
      "Epoch 8, Batch 46, Generator Loss: 0.7248309254646301, Discriminator Loss: 1.2983777523040771\n",
      "Epoch 8, Batch 47, Generator Loss: 0.7230715751647949, Discriminator Loss: 1.3195815086364746\n",
      "Epoch 8, Batch 48, Generator Loss: 0.7315741181373596, Discriminator Loss: 1.3310974836349487\n",
      "Epoch 8, Batch 49, Generator Loss: 0.7259869575500488, Discriminator Loss: 1.3268237113952637\n",
      "Epoch 8, Batch 50, Generator Loss: 0.7262693643569946, Discriminator Loss: 1.266149878501892\n",
      "Epoch 8, Batch 51, Generator Loss: 0.7360896468162537, Discriminator Loss: 1.3718645572662354\n",
      "Epoch 8, Batch 52, Generator Loss: 0.7338910102844238, Discriminator Loss: 1.272769808769226\n",
      "Epoch 8, Batch 53, Generator Loss: 0.7200524806976318, Discriminator Loss: 1.330315351486206\n",
      "Epoch 8, Batch 54, Generator Loss: 0.7239447832107544, Discriminator Loss: 1.3598229885101318\n",
      "Epoch 8, Batch 55, Generator Loss: 0.7290084362030029, Discriminator Loss: 1.2822365760803223\n",
      "Epoch 8, Batch 56, Generator Loss: 0.7239408493041992, Discriminator Loss: 1.387182593345642\n",
      "Epoch 8, Batch 57, Generator Loss: 0.7288941144943237, Discriminator Loss: 1.3156780004501343\n",
      "Epoch 8, Batch 58, Generator Loss: 0.7378871440887451, Discriminator Loss: 1.2883124351501465\n",
      "Epoch 8, Batch 59, Generator Loss: 0.7251332998275757, Discriminator Loss: 1.3017151355743408\n",
      "Epoch 8, Batch 60, Generator Loss: 0.7306645512580872, Discriminator Loss: 1.3466774225234985\n",
      "Epoch 8, Batch 61, Generator Loss: 0.7400382161140442, Discriminator Loss: 1.2683746814727783\n",
      "Epoch 8, Batch 62, Generator Loss: 0.7338452339172363, Discriminator Loss: 1.3100812435150146\n",
      "Epoch 8, Batch 63, Generator Loss: 0.7342183589935303, Discriminator Loss: 1.3093712329864502\n",
      "Epoch 8, Batch 64, Generator Loss: 0.7371088862419128, Discriminator Loss: 1.3563783168792725\n",
      "Epoch 8, Batch 65, Generator Loss: 0.7317982316017151, Discriminator Loss: 1.2866441011428833\n",
      "Epoch 8, Batch 66, Generator Loss: 0.7252095341682434, Discriminator Loss: 1.369600772857666\n",
      "Epoch 8, Batch 67, Generator Loss: 0.730302631855011, Discriminator Loss: 1.3530464172363281\n",
      "Epoch 8, Batch 68, Generator Loss: 0.7336082458496094, Discriminator Loss: 1.3704111576080322\n",
      "Epoch 8, Batch 69, Generator Loss: 0.7464474439620972, Discriminator Loss: 1.2967228889465332\n",
      "Epoch 8, Batch 70, Generator Loss: 0.7312151789665222, Discriminator Loss: 1.281177043914795\n",
      "Epoch 8, Batch 71, Generator Loss: 0.7413758039474487, Discriminator Loss: 1.3097329139709473\n",
      "Epoch 8, Batch 72, Generator Loss: 0.7308987379074097, Discriminator Loss: 1.39462411403656\n",
      "Epoch 8, Batch 73, Generator Loss: 0.731641411781311, Discriminator Loss: 1.3850693702697754\n",
      "Epoch 8, Batch 74, Generator Loss: 0.7466161251068115, Discriminator Loss: 1.3736071586608887\n",
      "Epoch 8, Batch 75, Generator Loss: 0.7314519882202148, Discriminator Loss: 1.3182177543640137\n",
      "Epoch 8, Batch 76, Generator Loss: 0.7398543357849121, Discriminator Loss: 1.3850486278533936\n",
      "Epoch 8, Batch 77, Generator Loss: 0.7386025190353394, Discriminator Loss: 1.397045373916626\n",
      "Epoch 8, Batch 78, Generator Loss: 0.7228790521621704, Discriminator Loss: 1.3808939456939697\n",
      "Epoch 8, Batch 79, Generator Loss: 0.7343815565109253, Discriminator Loss: 1.3748799562454224\n",
      "Epoch 8, Batch 80, Generator Loss: 0.7347462177276611, Discriminator Loss: 1.3711917400360107\n",
      "Epoch 8, Batch 81, Generator Loss: 0.7374211549758911, Discriminator Loss: 1.3562742471694946\n",
      "Epoch 8, Batch 82, Generator Loss: 0.7467823624610901, Discriminator Loss: 1.284811019897461\n",
      "Epoch 8, Batch 83, Generator Loss: 0.7315621376037598, Discriminator Loss: 1.3528265953063965\n",
      "Epoch 8, Batch 84, Generator Loss: 0.7411162853240967, Discriminator Loss: 1.3886629343032837\n",
      "Epoch 8, Batch 85, Generator Loss: 0.7373272776603699, Discriminator Loss: 1.2899802923202515\n",
      "Epoch 8, Batch 86, Generator Loss: 0.7254723310470581, Discriminator Loss: 1.398712158203125\n",
      "Epoch 8, Batch 87, Generator Loss: 0.7324513792991638, Discriminator Loss: 1.2984645366668701\n",
      "Epoch 8, Batch 88, Generator Loss: 0.7440824508666992, Discriminator Loss: 1.2843717336654663\n",
      "Epoch 8, Batch 89, Generator Loss: 0.735971212387085, Discriminator Loss: 1.3481639623641968\n",
      "Epoch 8, Batch 90, Generator Loss: 0.7386611104011536, Discriminator Loss: 1.3188530206680298\n",
      "Epoch 8, Batch 91, Generator Loss: 0.7363137006759644, Discriminator Loss: 1.3879896402359009\n",
      "Epoch 9, Batch 1, Generator Loss: 0.7281423807144165, Discriminator Loss: 1.3249499797821045\n",
      "Epoch 9, Batch 2, Generator Loss: 0.7420278787612915, Discriminator Loss: 1.331895351409912\n",
      "Epoch 9, Batch 3, Generator Loss: 0.730294942855835, Discriminator Loss: 1.2854595184326172\n",
      "Epoch 9, Batch 4, Generator Loss: 0.7531783580780029, Discriminator Loss: 1.3110573291778564\n",
      "Epoch 9, Batch 5, Generator Loss: 0.740384578704834, Discriminator Loss: 1.3384394645690918\n",
      "Epoch 9, Batch 6, Generator Loss: 0.7351536154747009, Discriminator Loss: 1.3585638999938965\n",
      "Epoch 9, Batch 7, Generator Loss: 0.7298375964164734, Discriminator Loss: 1.3356540203094482\n",
      "Epoch 9, Batch 8, Generator Loss: 0.7396811246871948, Discriminator Loss: 1.3234286308288574\n",
      "Epoch 9, Batch 9, Generator Loss: 0.7355852723121643, Discriminator Loss: 1.3439935445785522\n",
      "Epoch 9, Batch 10, Generator Loss: 0.7260987758636475, Discriminator Loss: 1.317775011062622\n",
      "Epoch 9, Batch 11, Generator Loss: 0.7250803709030151, Discriminator Loss: 1.344167947769165\n",
      "Epoch 9, Batch 12, Generator Loss: 0.7330160140991211, Discriminator Loss: 1.3621609210968018\n",
      "Epoch 9, Batch 13, Generator Loss: 0.7328618764877319, Discriminator Loss: 1.3277509212493896\n",
      "Epoch 9, Batch 14, Generator Loss: 0.7432658672332764, Discriminator Loss: 1.3275635242462158\n",
      "Epoch 9, Batch 15, Generator Loss: 0.7285473942756653, Discriminator Loss: 1.345320224761963\n",
      "Epoch 9, Batch 16, Generator Loss: 0.7407253980636597, Discriminator Loss: 1.3242604732513428\n",
      "Epoch 9, Batch 17, Generator Loss: 0.7337704300880432, Discriminator Loss: 1.3411476612091064\n",
      "Epoch 9, Batch 18, Generator Loss: 0.7332217693328857, Discriminator Loss: 1.2657194137573242\n",
      "Epoch 9, Batch 19, Generator Loss: 0.736518383026123, Discriminator Loss: 1.3583111763000488\n",
      "Epoch 9, Batch 20, Generator Loss: 0.7494451403617859, Discriminator Loss: 1.2720855474472046\n",
      "Epoch 9, Batch 21, Generator Loss: 0.7255070209503174, Discriminator Loss: 1.338935136795044\n",
      "Epoch 9, Batch 22, Generator Loss: 0.7237464189529419, Discriminator Loss: 1.369485855102539\n",
      "Epoch 9, Batch 23, Generator Loss: 0.7291483879089355, Discriminator Loss: 1.3684815168380737\n",
      "Epoch 9, Batch 24, Generator Loss: 0.7264949679374695, Discriminator Loss: 1.3379974365234375\n",
      "Epoch 9, Batch 25, Generator Loss: 0.7441748380661011, Discriminator Loss: 1.3280051946640015\n",
      "Epoch 9, Batch 26, Generator Loss: 0.735550582408905, Discriminator Loss: 1.3810588121414185\n",
      "Epoch 9, Batch 27, Generator Loss: 0.7385773658752441, Discriminator Loss: 1.352651834487915\n",
      "Epoch 9, Batch 28, Generator Loss: 0.7413967847824097, Discriminator Loss: 1.3183197975158691\n",
      "Epoch 9, Batch 29, Generator Loss: 0.7286832332611084, Discriminator Loss: 1.3049428462982178\n",
      "Epoch 9, Batch 30, Generator Loss: 0.7356216907501221, Discriminator Loss: 1.3720602989196777\n",
      "Epoch 9, Batch 31, Generator Loss: 0.7276279926300049, Discriminator Loss: 1.3455551862716675\n",
      "Epoch 9, Batch 32, Generator Loss: 0.7283381223678589, Discriminator Loss: 1.3659567832946777\n",
      "Epoch 9, Batch 33, Generator Loss: 0.7371395230293274, Discriminator Loss: 1.3360073566436768\n",
      "Epoch 9, Batch 34, Generator Loss: 0.7377309799194336, Discriminator Loss: 1.3680142164230347\n",
      "Epoch 9, Batch 35, Generator Loss: 0.7372915744781494, Discriminator Loss: 1.3037447929382324\n",
      "Epoch 9, Batch 36, Generator Loss: 0.7225863933563232, Discriminator Loss: 1.3087193965911865\n",
      "Epoch 9, Batch 37, Generator Loss: 0.7364660501480103, Discriminator Loss: 1.3509857654571533\n",
      "Epoch 9, Batch 38, Generator Loss: 0.7347764372825623, Discriminator Loss: 1.304030179977417\n",
      "Epoch 9, Batch 39, Generator Loss: 0.7517336010932922, Discriminator Loss: 1.3610098361968994\n",
      "Epoch 9, Batch 40, Generator Loss: 0.7444478273391724, Discriminator Loss: 1.3542931079864502\n",
      "Epoch 9, Batch 41, Generator Loss: 0.7493811845779419, Discriminator Loss: 1.3491199016571045\n",
      "Epoch 9, Batch 42, Generator Loss: 0.720569908618927, Discriminator Loss: 1.3691256046295166\n",
      "Epoch 9, Batch 43, Generator Loss: 0.7297250032424927, Discriminator Loss: 1.383057713508606\n",
      "Epoch 9, Batch 44, Generator Loss: 0.7263554930686951, Discriminator Loss: 1.315183401107788\n",
      "Epoch 9, Batch 45, Generator Loss: 0.7312730550765991, Discriminator Loss: 1.2782092094421387\n",
      "Epoch 9, Batch 46, Generator Loss: 0.7308774590492249, Discriminator Loss: 1.2859071493148804\n",
      "Epoch 9, Batch 47, Generator Loss: 0.7427839040756226, Discriminator Loss: 1.3042869567871094\n",
      "Epoch 9, Batch 48, Generator Loss: 0.7313407063484192, Discriminator Loss: 1.32289719581604\n",
      "Epoch 9, Batch 49, Generator Loss: 0.7465943098068237, Discriminator Loss: 1.3131368160247803\n",
      "Epoch 9, Batch 50, Generator Loss: 0.7362818717956543, Discriminator Loss: 1.2474958896636963\n",
      "Epoch 9, Batch 51, Generator Loss: 0.7322521209716797, Discriminator Loss: 1.3771328926086426\n",
      "Epoch 9, Batch 52, Generator Loss: 0.7272109389305115, Discriminator Loss: 1.2718634605407715\n",
      "Epoch 9, Batch 53, Generator Loss: 0.7412760257720947, Discriminator Loss: 1.3014814853668213\n",
      "Epoch 9, Batch 54, Generator Loss: 0.7385523319244385, Discriminator Loss: 1.3494620323181152\n",
      "Epoch 9, Batch 55, Generator Loss: 0.7413069605827332, Discriminator Loss: 1.2662889957427979\n",
      "Epoch 9, Batch 56, Generator Loss: 0.7467237710952759, Discriminator Loss: 1.3691840171813965\n",
      "Epoch 9, Batch 57, Generator Loss: 0.7384051084518433, Discriminator Loss: 1.301184058189392\n",
      "Epoch 9, Batch 58, Generator Loss: 0.7339518070220947, Discriminator Loss: 1.2824370861053467\n",
      "Epoch 9, Batch 59, Generator Loss: 0.7223683595657349, Discriminator Loss: 1.2967379093170166\n",
      "Epoch 9, Batch 60, Generator Loss: 0.7397257089614868, Discriminator Loss: 1.338537573814392\n",
      "Epoch 9, Batch 61, Generator Loss: 0.7301210165023804, Discriminator Loss: 1.2703535556793213\n",
      "Epoch 9, Batch 62, Generator Loss: 0.740289032459259, Discriminator Loss: 1.3027338981628418\n",
      "Epoch 9, Batch 63, Generator Loss: 0.734178900718689, Discriminator Loss: 1.3001644611358643\n",
      "Epoch 9, Batch 64, Generator Loss: 0.7365162372589111, Discriminator Loss: 1.355219841003418\n",
      "Epoch 9, Batch 65, Generator Loss: 0.7379690408706665, Discriminator Loss: 1.2735127210617065\n",
      "Epoch 9, Batch 66, Generator Loss: 0.7465718984603882, Discriminator Loss: 1.34505033493042\n",
      "Epoch 9, Batch 67, Generator Loss: 0.7369012236595154, Discriminator Loss: 1.3448677062988281\n",
      "Epoch 9, Batch 68, Generator Loss: 0.733381986618042, Discriminator Loss: 1.3617160320281982\n",
      "Epoch 9, Batch 69, Generator Loss: 0.7383946180343628, Discriminator Loss: 1.294896125793457\n",
      "Epoch 9, Batch 70, Generator Loss: 0.7369909286499023, Discriminator Loss: 1.2613732814788818\n",
      "Epoch 9, Batch 71, Generator Loss: 0.7427384853363037, Discriminator Loss: 1.307490587234497\n",
      "Epoch 9, Batch 72, Generator Loss: 0.7373816967010498, Discriminator Loss: 1.3878920078277588\n",
      "Epoch 9, Batch 73, Generator Loss: 0.7387048006057739, Discriminator Loss: 1.3844355344772339\n",
      "Epoch 9, Batch 74, Generator Loss: 0.7332582473754883, Discriminator Loss: 1.3902771472930908\n",
      "Epoch 9, Batch 75, Generator Loss: 0.7290992736816406, Discriminator Loss: 1.3246369361877441\n",
      "Epoch 9, Batch 76, Generator Loss: 0.7347791194915771, Discriminator Loss: 1.3847146034240723\n",
      "Epoch 9, Batch 77, Generator Loss: 0.7323548197746277, Discriminator Loss: 1.4036221504211426\n",
      "Epoch 9, Batch 78, Generator Loss: 0.7369981408119202, Discriminator Loss: 1.3713951110839844\n",
      "Epoch 9, Batch 79, Generator Loss: 0.7334413528442383, Discriminator Loss: 1.3792662620544434\n",
      "Epoch 9, Batch 80, Generator Loss: 0.7371890544891357, Discriminator Loss: 1.3682832717895508\n",
      "Epoch 9, Batch 81, Generator Loss: 0.7386661171913147, Discriminator Loss: 1.3535016775131226\n",
      "Epoch 9, Batch 82, Generator Loss: 0.7323195934295654, Discriminator Loss: 1.2903499603271484\n",
      "Epoch 9, Batch 83, Generator Loss: 0.7398256063461304, Discriminator Loss: 1.3411226272583008\n",
      "Epoch 9, Batch 84, Generator Loss: 0.7270696759223938, Discriminator Loss: 1.3950045108795166\n",
      "Epoch 9, Batch 85, Generator Loss: 0.7333001494407654, Discriminator Loss: 1.283198595046997\n",
      "Epoch 9, Batch 86, Generator Loss: 0.729212760925293, Discriminator Loss: 1.3982532024383545\n",
      "Epoch 9, Batch 87, Generator Loss: 0.7373415231704712, Discriminator Loss: 1.2889326810836792\n",
      "Epoch 9, Batch 88, Generator Loss: 0.7256656885147095, Discriminator Loss: 1.292668342590332\n",
      "Epoch 9, Batch 89, Generator Loss: 0.743004322052002, Discriminator Loss: 1.3404552936553955\n",
      "Epoch 9, Batch 90, Generator Loss: 0.7269899845123291, Discriminator Loss: 1.3243589401245117\n",
      "Epoch 9, Batch 91, Generator Loss: 0.7317203283309937, Discriminator Loss: 1.3888323307037354\n",
      "Epoch 10, Batch 1, Generator Loss: 0.7390975952148438, Discriminator Loss: 1.3158403635025024\n",
      "Epoch 10, Batch 2, Generator Loss: 0.726110577583313, Discriminator Loss: 1.3469548225402832\n",
      "Epoch 10, Batch 3, Generator Loss: 0.738498330116272, Discriminator Loss: 1.2738728523254395\n",
      "Epoch 10, Batch 4, Generator Loss: 0.7412884831428528, Discriminator Loss: 1.3280049562454224\n",
      "Epoch 10, Batch 5, Generator Loss: 0.7509702444076538, Discriminator Loss: 1.3169511556625366\n",
      "Epoch 10, Batch 6, Generator Loss: 0.7450989484786987, Discriminator Loss: 1.3456459045410156\n",
      "Epoch 10, Batch 7, Generator Loss: 0.7354539036750793, Discriminator Loss: 1.3232553005218506\n",
      "Epoch 10, Batch 8, Generator Loss: 0.7480541467666626, Discriminator Loss: 1.307861328125\n",
      "Epoch 10, Batch 9, Generator Loss: 0.7526808381080627, Discriminator Loss: 1.3271565437316895\n",
      "Epoch 10, Batch 10, Generator Loss: 0.7327456474304199, Discriminator Loss: 1.3108363151550293\n",
      "Epoch 10, Batch 11, Generator Loss: 0.732088565826416, Discriminator Loss: 1.3380303382873535\n",
      "Epoch 10, Batch 12, Generator Loss: 0.7314679026603699, Discriminator Loss: 1.3584182262420654\n",
      "Epoch 10, Batch 13, Generator Loss: 0.7382664084434509, Discriminator Loss: 1.3180420398712158\n",
      "Epoch 10, Batch 14, Generator Loss: 0.737592339515686, Discriminator Loss: 1.3229007720947266\n",
      "Epoch 10, Batch 15, Generator Loss: 0.7428823709487915, Discriminator Loss: 1.3274378776550293\n",
      "Epoch 10, Batch 16, Generator Loss: 0.7249659299850464, Discriminator Loss: 1.33426833152771\n",
      "Epoch 10, Batch 17, Generator Loss: 0.7271029353141785, Discriminator Loss: 1.3462955951690674\n",
      "Epoch 10, Batch 18, Generator Loss: 0.747401237487793, Discriminator Loss: 1.2491334676742554\n",
      "Epoch 10, Batch 19, Generator Loss: 0.735929012298584, Discriminator Loss: 1.3590419292449951\n",
      "Epoch 10, Batch 20, Generator Loss: 0.7471731901168823, Discriminator Loss: 1.2580382823944092\n",
      "Epoch 10, Batch 21, Generator Loss: 0.7259926795959473, Discriminator Loss: 1.3327585458755493\n",
      "Epoch 10, Batch 22, Generator Loss: 0.7341817617416382, Discriminator Loss: 1.356087327003479\n",
      "Epoch 10, Batch 23, Generator Loss: 0.7341667413711548, Discriminator Loss: 1.3592803478240967\n",
      "Epoch 10, Batch 24, Generator Loss: 0.7399021983146667, Discriminator Loss: 1.3141248226165771\n",
      "Epoch 10, Batch 25, Generator Loss: 0.721866250038147, Discriminator Loss: 1.3443657159805298\n",
      "Epoch 10, Batch 26, Generator Loss: 0.7289832234382629, Discriminator Loss: 1.3791747093200684\n",
      "Epoch 10, Batch 27, Generator Loss: 0.7473036050796509, Discriminator Loss: 1.3480839729309082\n",
      "Epoch 10, Batch 28, Generator Loss: 0.7284361124038696, Discriminator Loss: 1.3198704719543457\n",
      "Epoch 10, Batch 29, Generator Loss: 0.7330503463745117, Discriminator Loss: 1.294735074043274\n",
      "Epoch 10, Batch 30, Generator Loss: 0.7335971593856812, Discriminator Loss: 1.37167489528656\n",
      "Epoch 10, Batch 31, Generator Loss: 0.7389088869094849, Discriminator Loss: 1.333847999572754\n",
      "Epoch 10, Batch 32, Generator Loss: 0.738756537437439, Discriminator Loss: 1.3555583953857422\n",
      "Epoch 10, Batch 33, Generator Loss: 0.7302221655845642, Discriminator Loss: 1.3411521911621094\n",
      "Epoch 10, Batch 34, Generator Loss: 0.7330365180969238, Discriminator Loss: 1.3589330911636353\n",
      "Epoch 10, Batch 35, Generator Loss: 0.7404365539550781, Discriminator Loss: 1.299213171005249\n",
      "Epoch 10, Batch 36, Generator Loss: 0.7333509922027588, Discriminator Loss: 1.2971097230911255\n",
      "Epoch 10, Batch 37, Generator Loss: 0.7367130517959595, Discriminator Loss: 1.3475539684295654\n",
      "Epoch 10, Batch 38, Generator Loss: 0.7418005466461182, Discriminator Loss: 1.2922874689102173\n",
      "Epoch 10, Batch 39, Generator Loss: 0.7451316714286804, Discriminator Loss: 1.3594213724136353\n",
      "Epoch 10, Batch 40, Generator Loss: 0.7261582612991333, Discriminator Loss: 1.3716846704483032\n",
      "Epoch 10, Batch 41, Generator Loss: 0.73133385181427, Discriminator Loss: 1.360795021057129\n",
      "Epoch 10, Batch 42, Generator Loss: 0.7254401445388794, Discriminator Loss: 1.3588054180145264\n",
      "Epoch 10, Batch 43, Generator Loss: 0.7498220801353455, Discriminator Loss: 1.3677771091461182\n",
      "Epoch 10, Batch 44, Generator Loss: 0.7464121580123901, Discriminator Loss: 1.2945287227630615\n",
      "Epoch 10, Batch 45, Generator Loss: 0.7258256077766418, Discriminator Loss: 1.2796703577041626\n",
      "Epoch 10, Batch 46, Generator Loss: 0.7392290830612183, Discriminator Loss: 1.2751610279083252\n",
      "Epoch 10, Batch 47, Generator Loss: 0.7427879571914673, Discriminator Loss: 1.2955806255340576\n",
      "Epoch 10, Batch 48, Generator Loss: 0.7209280729293823, Discriminator Loss: 1.32991361618042\n",
      "Epoch 10, Batch 49, Generator Loss: 0.7382087111473083, Discriminator Loss: 1.3120627403259277\n",
      "Epoch 10, Batch 50, Generator Loss: 0.7343864440917969, Discriminator Loss: 1.2443528175354004\n",
      "Epoch 10, Batch 51, Generator Loss: 0.7358699440956116, Discriminator Loss: 1.371840238571167\n",
      "Epoch 10, Batch 52, Generator Loss: 0.7450821399688721, Discriminator Loss: 1.2542304992675781\n",
      "Epoch 10, Batch 53, Generator Loss: 0.7377299666404724, Discriminator Loss: 1.2993462085723877\n",
      "Epoch 10, Batch 54, Generator Loss: 0.7460523843765259, Discriminator Loss: 1.34445059299469\n",
      "Epoch 10, Batch 55, Generator Loss: 0.7416839599609375, Discriminator Loss: 1.2559300661087036\n",
      "Epoch 10, Batch 56, Generator Loss: 0.7305285930633545, Discriminator Loss: 1.380644679069519\n",
      "Epoch 10, Batch 57, Generator Loss: 0.7375402450561523, Discriminator Loss: 1.2991626262664795\n",
      "Epoch 10, Batch 58, Generator Loss: 0.7438709139823914, Discriminator Loss: 1.2709197998046875\n",
      "Epoch 10, Batch 59, Generator Loss: 0.737978458404541, Discriminator Loss: 1.2825639247894287\n",
      "Epoch 10, Batch 60, Generator Loss: 0.7368572354316711, Discriminator Loss: 1.3407429456710815\n",
      "Epoch 10, Batch 61, Generator Loss: 0.739345908164978, Discriminator Loss: 1.2527130842208862\n",
      "Epoch 10, Batch 62, Generator Loss: 0.7397837042808533, Discriminator Loss: 1.2945066690444946\n",
      "Epoch 10, Batch 63, Generator Loss: 0.7320127487182617, Discriminator Loss: 1.300858974456787\n",
      "Epoch 10, Batch 64, Generator Loss: 0.7386647462844849, Discriminator Loss: 1.3526716232299805\n",
      "Epoch 10, Batch 65, Generator Loss: 0.7545621991157532, Discriminator Loss: 1.2537729740142822\n",
      "Epoch 10, Batch 66, Generator Loss: 0.7415299415588379, Discriminator Loss: 1.3487941026687622\n",
      "Epoch 10, Batch 67, Generator Loss: 0.7439644932746887, Discriminator Loss: 1.3429207801818848\n",
      "Epoch 10, Batch 68, Generator Loss: 0.7438275218009949, Discriminator Loss: 1.3585848808288574\n",
      "Epoch 10, Batch 69, Generator Loss: 0.7254441976547241, Discriminator Loss: 1.300248146057129\n",
      "Epoch 10, Batch 70, Generator Loss: 0.7413734197616577, Discriminator Loss: 1.2542850971221924\n",
      "Epoch 10, Batch 71, Generator Loss: 0.7382671236991882, Discriminator Loss: 1.3018379211425781\n",
      "Epoch 10, Batch 72, Generator Loss: 0.740156888961792, Discriminator Loss: 1.3876360654830933\n",
      "Epoch 10, Batch 73, Generator Loss: 0.7336125373840332, Discriminator Loss: 1.3889312744140625\n",
      "Epoch 10, Batch 74, Generator Loss: 0.7483599185943604, Discriminator Loss: 1.375304937362671\n",
      "Epoch 10, Batch 75, Generator Loss: 0.7317004799842834, Discriminator Loss: 1.3077385425567627\n",
      "Epoch 10, Batch 76, Generator Loss: 0.749788761138916, Discriminator Loss: 1.3727610111236572\n",
      "Epoch 10, Batch 77, Generator Loss: 0.7415205240249634, Discriminator Loss: 1.3993535041809082\n",
      "Epoch 10, Batch 78, Generator Loss: 0.7452458143234253, Discriminator Loss: 1.365785837173462\n",
      "Epoch 10, Batch 79, Generator Loss: 0.7349905371665955, Discriminator Loss: 1.3747694492340088\n",
      "Epoch 10, Batch 80, Generator Loss: 0.7347046732902527, Discriminator Loss: 1.3720476627349854\n",
      "Epoch 10, Batch 81, Generator Loss: 0.7401832938194275, Discriminator Loss: 1.3461426496505737\n",
      "Epoch 10, Batch 82, Generator Loss: 0.7415131330490112, Discriminator Loss: 1.277502417564392\n",
      "Epoch 10, Batch 83, Generator Loss: 0.7358185052871704, Discriminator Loss: 1.3469854593276978\n",
      "Epoch 10, Batch 84, Generator Loss: 0.7422316670417786, Discriminator Loss: 1.3873870372772217\n",
      "Epoch 10, Batch 85, Generator Loss: 0.7428491115570068, Discriminator Loss: 1.2695860862731934\n",
      "Epoch 10, Batch 86, Generator Loss: 0.7527231574058533, Discriminator Loss: 1.3780252933502197\n",
      "Epoch 10, Batch 87, Generator Loss: 0.7474699020385742, Discriminator Loss: 1.280998945236206\n",
      "Epoch 10, Batch 88, Generator Loss: 0.7375773191452026, Discriminator Loss: 1.2777544260025024\n",
      "Epoch 10, Batch 89, Generator Loss: 0.7505649328231812, Discriminator Loss: 1.334167242050171\n",
      "Epoch 10, Batch 90, Generator Loss: 0.7484066486358643, Discriminator Loss: 1.3055176734924316\n",
      "Epoch 10, Batch 91, Generator Loss: 0.7546403408050537, Discriminator Loss: 1.368300199508667\n",
      "Epoch 11, Batch 1, Generator Loss: 0.7329403162002563, Discriminator Loss: 1.3204216957092285\n",
      "Epoch 11, Batch 2, Generator Loss: 0.7538334131240845, Discriminator Loss: 1.3150407075881958\n",
      "Epoch 11, Batch 3, Generator Loss: 0.7390726804733276, Discriminator Loss: 1.269814372062683\n",
      "Epoch 11, Batch 4, Generator Loss: 0.7395178079605103, Discriminator Loss: 1.315314531326294\n",
      "Epoch 11, Batch 5, Generator Loss: 0.738099217414856, Discriminator Loss: 1.3235511779785156\n",
      "Epoch 11, Batch 6, Generator Loss: 0.7436896562576294, Discriminator Loss: 1.3394718170166016\n",
      "Epoch 11, Batch 7, Generator Loss: 0.734738826751709, Discriminator Loss: 1.3189517259597778\n",
      "Epoch 11, Batch 8, Generator Loss: 0.7364794015884399, Discriminator Loss: 1.3173683881759644\n",
      "Epoch 11, Batch 9, Generator Loss: 0.735325813293457, Discriminator Loss: 1.3324604034423828\n",
      "Epoch 11, Batch 10, Generator Loss: 0.7439773082733154, Discriminator Loss: 1.2948135137557983\n",
      "Epoch 11, Batch 11, Generator Loss: 0.732460081577301, Discriminator Loss: 1.3347642421722412\n",
      "Epoch 11, Batch 12, Generator Loss: 0.7416088581085205, Discriminator Loss: 1.3479689359664917\n",
      "Epoch 11, Batch 13, Generator Loss: 0.7436822652816772, Discriminator Loss: 1.306919813156128\n",
      "Epoch 11, Batch 14, Generator Loss: 0.7482204437255859, Discriminator Loss: 1.3115367889404297\n",
      "Epoch 11, Batch 15, Generator Loss: 0.7301428318023682, Discriminator Loss: 1.3376026153564453\n",
      "Epoch 11, Batch 16, Generator Loss: 0.7336995005607605, Discriminator Loss: 1.3227286338806152\n",
      "Epoch 11, Batch 17, Generator Loss: 0.7269749641418457, Discriminator Loss: 1.342230200767517\n",
      "Epoch 11, Batch 18, Generator Loss: 0.7444133758544922, Discriminator Loss: 1.2481269836425781\n",
      "Epoch 11, Batch 19, Generator Loss: 0.7496660351753235, Discriminator Loss: 1.341301679611206\n",
      "Epoch 11, Batch 20, Generator Loss: 0.7431652545928955, Discriminator Loss: 1.2662608623504639\n",
      "Epoch 11, Batch 21, Generator Loss: 0.7304223775863647, Discriminator Loss: 1.3230476379394531\n",
      "Epoch 11, Batch 22, Generator Loss: 0.7478302717208862, Discriminator Loss: 1.348367691040039\n",
      "Epoch 11, Batch 23, Generator Loss: 0.732745349407196, Discriminator Loss: 1.358001947402954\n",
      "Epoch 11, Batch 24, Generator Loss: 0.7408060431480408, Discriminator Loss: 1.313784122467041\n",
      "Epoch 11, Batch 25, Generator Loss: 0.7416516542434692, Discriminator Loss: 1.319310188293457\n",
      "Epoch 11, Batch 26, Generator Loss: 0.7485986948013306, Discriminator Loss: 1.363809585571289\n",
      "Epoch 11, Batch 27, Generator Loss: 0.7425364851951599, Discriminator Loss: 1.3523470163345337\n",
      "Epoch 11, Batch 28, Generator Loss: 0.7402236461639404, Discriminator Loss: 1.304518461227417\n",
      "Epoch 11, Batch 29, Generator Loss: 0.7484469413757324, Discriminator Loss: 1.2800347805023193\n",
      "Epoch 11, Batch 30, Generator Loss: 0.7620239853858948, Discriminator Loss: 1.3435534238815308\n",
      "Epoch 11, Batch 31, Generator Loss: 0.7345010638237, Discriminator Loss: 1.3316700458526611\n",
      "Epoch 11, Batch 32, Generator Loss: 0.7415752410888672, Discriminator Loss: 1.34712815284729\n",
      "Epoch 11, Batch 33, Generator Loss: 0.747361958026886, Discriminator Loss: 1.3222484588623047\n",
      "Epoch 11, Batch 34, Generator Loss: 0.7428621053695679, Discriminator Loss: 1.3475375175476074\n",
      "Epoch 11, Batch 35, Generator Loss: 0.747002124786377, Discriminator Loss: 1.2947734594345093\n",
      "Epoch 11, Batch 36, Generator Loss: 0.7395818829536438, Discriminator Loss: 1.2826011180877686\n",
      "Epoch 11, Batch 37, Generator Loss: 0.7457622289657593, Discriminator Loss: 1.335981011390686\n",
      "Epoch 11, Batch 38, Generator Loss: 0.7400097846984863, Discriminator Loss: 1.2828500270843506\n",
      "Epoch 11, Batch 39, Generator Loss: 0.7230968475341797, Discriminator Loss: 1.3816587924957275\n",
      "Epoch 11, Batch 40, Generator Loss: 0.7377163171768188, Discriminator Loss: 1.3617613315582275\n",
      "Epoch 11, Batch 41, Generator Loss: 0.734146237373352, Discriminator Loss: 1.3578250408172607\n",
      "Epoch 11, Batch 42, Generator Loss: 0.7455308437347412, Discriminator Loss: 1.3352117538452148\n",
      "Epoch 11, Batch 43, Generator Loss: 0.7428345084190369, Discriminator Loss: 1.3758606910705566\n",
      "Epoch 11, Batch 44, Generator Loss: 0.7475401163101196, Discriminator Loss: 1.2922022342681885\n",
      "Epoch 11, Batch 45, Generator Loss: 0.7418497204780579, Discriminator Loss: 1.257791519165039\n",
      "Epoch 11, Batch 46, Generator Loss: 0.7353619337081909, Discriminator Loss: 1.2752156257629395\n",
      "Epoch 11, Batch 47, Generator Loss: 0.7384117841720581, Discriminator Loss: 1.2956067323684692\n",
      "Epoch 11, Batch 48, Generator Loss: 0.7245009541511536, Discriminator Loss: 1.3174805641174316\n",
      "Epoch 11, Batch 49, Generator Loss: 0.7391303777694702, Discriminator Loss: 1.311357021331787\n",
      "Epoch 11, Batch 50, Generator Loss: 0.7348251342773438, Discriminator Loss: 1.2414674758911133\n",
      "Epoch 11, Batch 51, Generator Loss: 0.7303048372268677, Discriminator Loss: 1.37812077999115\n",
      "Epoch 11, Batch 52, Generator Loss: 0.7402840852737427, Discriminator Loss: 1.2460236549377441\n",
      "Epoch 11, Batch 53, Generator Loss: 0.7337305545806885, Discriminator Loss: 1.3046321868896484\n",
      "Epoch 11, Batch 54, Generator Loss: 0.7467160224914551, Discriminator Loss: 1.3413238525390625\n",
      "Epoch 11, Batch 55, Generator Loss: 0.7392526865005493, Discriminator Loss: 1.2523715496063232\n",
      "Epoch 11, Batch 56, Generator Loss: 0.7391635179519653, Discriminator Loss: 1.3767590522766113\n",
      "Epoch 11, Batch 57, Generator Loss: 0.7476695775985718, Discriminator Loss: 1.2844635248184204\n",
      "Epoch 11, Batch 58, Generator Loss: 0.7289853692054749, Discriminator Loss: 1.276832103729248\n",
      "Epoch 11, Batch 59, Generator Loss: 0.7242543697357178, Discriminator Loss: 1.2923424243927002\n",
      "Epoch 11, Batch 60, Generator Loss: 0.7355940341949463, Discriminator Loss: 1.3313508033752441\n",
      "Epoch 11, Batch 61, Generator Loss: 0.7469812631607056, Discriminator Loss: 1.2412189245224\n",
      "Epoch 11, Batch 62, Generator Loss: 0.7484390735626221, Discriminator Loss: 1.2809593677520752\n",
      "Epoch 11, Batch 63, Generator Loss: 0.747355580329895, Discriminator Loss: 1.2800966501235962\n",
      "Epoch 11, Batch 64, Generator Loss: 0.7421589493751526, Discriminator Loss: 1.3546935319900513\n",
      "Epoch 11, Batch 65, Generator Loss: 0.7500237822532654, Discriminator Loss: 1.2496775388717651\n",
      "Epoch 11, Batch 66, Generator Loss: 0.7393760681152344, Discriminator Loss: 1.3433032035827637\n",
      "Epoch 11, Batch 67, Generator Loss: 0.7451387643814087, Discriminator Loss: 1.339393138885498\n",
      "Epoch 11, Batch 68, Generator Loss: 0.7371824383735657, Discriminator Loss: 1.3606455326080322\n",
      "Epoch 11, Batch 69, Generator Loss: 0.7437794208526611, Discriminator Loss: 1.2820173501968384\n",
      "Epoch 11, Batch 70, Generator Loss: 0.7417217493057251, Discriminator Loss: 1.2429800033569336\n",
      "Epoch 11, Batch 71, Generator Loss: 0.7331706881523132, Discriminator Loss: 1.3081130981445312\n",
      "Epoch 11, Batch 72, Generator Loss: 0.7504210472106934, Discriminator Loss: 1.374824047088623\n",
      "Epoch 11, Batch 73, Generator Loss: 0.739608645439148, Discriminator Loss: 1.3809597492218018\n",
      "Epoch 11, Batch 74, Generator Loss: 0.7448680996894836, Discriminator Loss: 1.38368821144104\n",
      "Epoch 11, Batch 75, Generator Loss: 0.7420612573623657, Discriminator Loss: 1.2927751541137695\n",
      "Epoch 11, Batch 76, Generator Loss: 0.7379642724990845, Discriminator Loss: 1.3818249702453613\n",
      "Epoch 11, Batch 77, Generator Loss: 0.7446621656417847, Discriminator Loss: 1.3944611549377441\n",
      "Epoch 11, Batch 78, Generator Loss: 0.7445164918899536, Discriminator Loss: 1.3630527257919312\n",
      "Epoch 11, Batch 79, Generator Loss: 0.7522227764129639, Discriminator Loss: 1.3638408184051514\n",
      "Epoch 11, Batch 80, Generator Loss: 0.7588180303573608, Discriminator Loss: 1.3524283170700073\n",
      "Epoch 11, Batch 81, Generator Loss: 0.7278215885162354, Discriminator Loss: 1.356547474861145\n",
      "Epoch 11, Batch 82, Generator Loss: 0.7525330185890198, Discriminator Loss: 1.2632067203521729\n",
      "Epoch 11, Batch 83, Generator Loss: 0.7521534562110901, Discriminator Loss: 1.3269672393798828\n",
      "Epoch 11, Batch 84, Generator Loss: 0.7502373456954956, Discriminator Loss: 1.3768303394317627\n",
      "Epoch 11, Batch 85, Generator Loss: 0.7469487190246582, Discriminator Loss: 1.2636138200759888\n",
      "Epoch 11, Batch 86, Generator Loss: 0.7448175549507141, Discriminator Loss: 1.3817040920257568\n",
      "Epoch 11, Batch 87, Generator Loss: 0.7420481443405151, Discriminator Loss: 1.2775743007659912\n",
      "Epoch 11, Batch 88, Generator Loss: 0.7579330801963806, Discriminator Loss: 1.2509300708770752\n",
      "Epoch 11, Batch 89, Generator Loss: 0.7452665567398071, Discriminator Loss: 1.3325982093811035\n",
      "Epoch 11, Batch 90, Generator Loss: 0.7467238903045654, Discriminator Loss: 1.3007159233093262\n",
      "Epoch 11, Batch 91, Generator Loss: 0.7335237264633179, Discriminator Loss: 1.3877925872802734\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define the Generator network\n",
    "def make_generator_model(Tx, num_features):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, input_shape=(100,), use_bias=False),  # Noise input\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dense(64),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dense(Tx * num_features),\n",
    "        layers.Reshape((Tx, num_features))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the Discriminator network\n",
    "def make_discriminator_model(Tx, num_features):\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(Tx, num_features)),  # Input sequence\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dense(64),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load time series data from CSV files\n",
    "path = r\"\\Users\\mahin\\Downloads\\Collected_data\"\n",
    "scenarios = []\n",
    "data_files = []\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        scenarios.append(folder)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    scenario_data = []\n",
    "    for file_name in os.listdir(os.path.join(path, scenario)):\n",
    "        file_path = os.path.join(path, scenario, file_name)\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_data = pd.read_csv(file_path)\n",
    "            scenario_data.append(file_data)\n",
    "    scenario_data = pd.concat(scenario_data, ignore_index=True)\n",
    "    data_files.append(scenario_data)\n",
    "\n",
    "# Parameters for data processing\n",
    "Tx = 20\n",
    "offset = 5\n",
    "stride = 1\n",
    "num_features = 5  # Number of features in the data\n",
    "\n",
    "# Prepare data for training GAN\n",
    "feature = []\n",
    "label = []\n",
    "\n",
    "for scenario_data in data_files:\n",
    "    j = 0\n",
    "    scenario_data['Connected'] = scenario_data['Connected'].apply(lambda x: 0 if x <= 0.75 else 1)\n",
    "    last_label = scenario_data['Connected'].iloc[-1]\n",
    "\n",
    "    while j + Tx <= scenario_data.shape[0] - offset:\n",
    "        feature.append(scenario_data[['linkQuality', 'neighborLinkQuality1', 'RSSI value', 'trend', 'tau']].iloc[j:j + Tx].values)\n",
    "        current_label_idx = j + Tx + offset - 1\n",
    "\n",
    "        if current_label_idx < scenario_data.shape[0]:\n",
    "            label.append(scenario_data['Connected'].iloc[current_label_idx])\n",
    "        else:\n",
    "            label.append(last_label)\n",
    "\n",
    "        j += stride\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(np.array(feature).reshape(-1, num_features)).reshape(-1, Tx, num_features)\n",
    "Y = np.array(label)\n",
    "\n",
    "# Create instances of the generator and discriminator\n",
    "generator = make_generator_model(Tx, num_features)\n",
    "discriminator = make_discriminator_model(Tx, num_features)\n",
    "\n",
    "# Define loss functions\n",
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# Define optimizers\n",
    "generator_optimizer = keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Training loop\n",
    "epochs = 11\n",
    "batch_size = 64\n",
    "noise_dim = 100  # Dimension of the noise input for the generator\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X) // batch_size):\n",
    "        real_data = X[i * batch_size : (i + 1) * batch_size]\n",
    "        real_labels = Y[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
    "            generated_data = generator(noise, training=True)\n",
    "\n",
    "            real_output = discriminator(real_data, training=True)\n",
    "            fake_output = discriminator(generated_data, training=True)\n",
    "\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Batch {i + 1}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}')\n",
    "\n",
    "# Generate synthetic data\n",
    "noise = np.random.normal(0, 1, (1000, noise_dim))\n",
    "synthetic_data = generator.predict(noise)\n",
    "\n",
    "# Inverse transform the synthetic data\n",
    "synthetic_data = scaler.inverse_transform(synthetic_data.reshape(-1, num_features)).reshape(-1, Tx, num_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
